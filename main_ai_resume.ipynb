{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import docx2txt\n",
    "import fitz\n",
    "import openai\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from docx import Document\n",
    "from docx.oxml.ns import nsdecls\n",
    "from docx.oxml import parse_xml\n",
    "from PyPDF2 import PdfReader,PdfWriter\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: '.env' file found and loaded successfully.\n",
      "INFO: OpenAI API key has been successfully set from an environment variable.\n"
     ]
    }
   ],
   "source": [
    "# Attempt to load environment variables from a .env file in the current directory\n",
    "# or any parent directories. This is useful for local development.\n",
    "# load_dotenv() will not override existing environment variables.\n",
    "dotenv_loaded_successfully = load_dotenv() \n",
    "\n",
    "if dotenv_loaded_successfully:\n",
    "    print(\"INFO: '.env' file found and loaded successfully.\")\n",
    "else:\n",
    "    print(\"INFO: No '.env' file found, or 'python-dotenv' is not installed. \"\n",
    "          \"Will rely on system environment variables for 'OPENAI_API_KEY'.\")\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variables.\n",
    "# os.getenv() will return None if the variable is not set.\n",
    "api_key_from_env = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key_from_env:\n",
    "    openai.api_key = api_key_from_env\n",
    "    print(\"INFO: OpenAI API key has been successfully set from an environment variable.\")\n",
    "    # For security reasons, do not print the key itself.\n",
    "    # You can print a part of it for verification if absolutely necessary during debugging,\n",
    "    # but remove it for final versions.\n",
    "    # print(f\"DEBUG: API Key starts with: {openai.api_key[:5]}...\") # Example for debugging\n",
    "else:\n",
    "    # If the API key is not found, print a critical error message with instructions.\n",
    "    # The script might still run, but subsequent OpenAI API calls will fail.\n",
    "    print(\"\\nCRITICAL ERROR: The 'OPENAI_API_KEY' environment variable is not set or not found.\")\n",
    "    print(\"Please ensure you have an OpenAI API key and have set it either as a system environment variable\")\n",
    "    print(\"or in a '.env' file in your project's root directory (e.g., OPENAI_API_KEY='sk-yourkey').\")\n",
    "    print(\"If using a .env file, ensure 'python-dotenv' is installed and 'load_dotenv()' is called.\")\n",
    "    # Depending on your script's structure, you might want to raise an error here to stop execution\n",
    "    # if the API key is absolutely essential for all subsequent steps.\n",
    "    # Example: raise ValueError(\"OpenAI API key not configured. Script cannot proceed.\")\n",
    "    print(\"WARNING: OpenAI API calls will fail until the API key is correctly configured.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Path Definitions ---\n",
    "job_description_folder = \"JD\" \n",
    "original_resumes_folder = \"original_resume\"\n",
    "sample_folder = \"sample_resume\"\n",
    "selected_resume_main_folder = \"selected_resume\"\n",
    "destination_folder = os.path.join(selected_resume_main_folder, datetime.date.today().isoformat())\n",
    "os.makedirs(destination_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file reading function\n",
    "def read_file(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Reads text content from a file, supporting .pdf and .docx formats.\n",
    "    Uses a 'with' statement for PDF files to ensure resources are properly managed.\n",
    "\n",
    "    Args:\n",
    "        path (str): The full path to the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted text content from the file.\n",
    "             Returns an empty string if the file type is not supported or an error occurs.\n",
    "    \"\"\"\n",
    "    text = \"\"  # Initialize text to ensure a string is always returned\n",
    "    \n",
    "    try:\n",
    "        if path.endswith(\".pdf\"):\n",
    "            # Use a 'with' statement to ensure the document is closed automatically,\n",
    "            # even if errors occur during processing.\n",
    "            with fitz.open(path) as doc:\n",
    "                all_pages_text = [page.get_text() for page in doc]\n",
    "                text = \"\\n\".join(all_pages_text)\n",
    "        elif path.endswith(\".docx\"):\n",
    "            text = docx2txt.process(path)\n",
    "        else:\n",
    "            # Handle unsupported file types\n",
    "            print(f\"Warning: Unsupported file type for: {os.path.basename(path)}. Only .pdf and .docx are currently processed.\")\n",
    "            # Depending on your needs, you might want to raise an error here instead of just printing.\n",
    "            # Example: raise ValueError(f\"Unsupported file type: {os.path.basename(path)}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{path}'\")\n",
    "    except fitz.fitz.FitzError as fe: # More specific error for PyMuPDF issues\n",
    "        print(f\"Error processing PDF file '{path}': {fe}\")\n",
    "    except Exception as e:\n",
    "        # Catch-all for other unexpected errors during file reading\n",
    "        print(f\"An unexpected error occurred while reading file '{path}': {e}\")\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Attempting to read Job Description from: c:\\Users\\harry\\OneDrive\\Desktop\\AI RESUME SCANNER\\AI_RESUME_SCANNER\\JD\\job_description.docx\n",
      "INFO: Successfully read Job Description: 'job_description.docx'\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Read and Validate Job Description (JD) ---\n",
    "\n",
    "# This cell is responsible for locating and reading the job description (JD) file.\n",
    "# The content of the JD is crucial as it serves as the primary reference for\n",
    "# evaluating both sample resumes and candidate resumes in subsequent steps.\n",
    "\n",
    "# Prerequisites:\n",
    "#   - 'job_description_folder': A string variable defined in a previous cell,\n",
    "#     containing the path to the directory where the JD file is stored.\n",
    "#   - 'read_file': A function defined in a previous cell, capable of extracting\n",
    "#     text from .docx and .pdf files.\n",
    "# Required imported modules:\n",
    "#   - 'os' (for os.path.join, os.path.exists, os.path.isfile, os.path.basename, os.path.abspath)\n",
    "#   - 'datetime' (if you were using it for any dynamic naming here, though not directly in this snippet)\n",
    "\n",
    "# --- Configuration for Job Description File ---\n",
    "# Define the expected filename for the job description.\n",
    "# This makes it easy to update if the filename changes.\n",
    "# Ensure this filename matches the actual file in your 'job_description_folder'.\n",
    "JOB_DESCRIPTION_FILENAME = \"job_description.docx\" # Or \"JD_Edited.docx\" if that's your active file\n",
    "\n",
    "# Construct the full, platform-independent path to the job description file.\n",
    "jd_path = os.path.join(job_description_folder, JOB_DESCRIPTION_FILENAME)\n",
    "\n",
    "# Initialize 'jd_full_text'. This variable will hold the text content of the JD.\n",
    "# Initializing to an empty string ensures it's always defined, even if file reading fails.\n",
    "jd_full_text = \"\" \n",
    "\n",
    "# --- Read and Validate Job Description File ---\n",
    "print(f\"INFO: Attempting to read Job Description from: {os.path.abspath(jd_path)}\")\n",
    "\n",
    "# Check if the constructed path to the JD file actually exists in the filesystem.\n",
    "if os.path.exists(jd_path):\n",
    "    # If the path exists, further check if it's a file (not a directory).\n",
    "    if os.path.isfile(jd_path):\n",
    "        # Attempt to read the text content from the file using the 'read_file' function.\n",
    "        # It's assumed 'read_file' will handle its own internal errors (e.g., unsupported types,\n",
    "        # corrupted files) and ideally return an empty string or raise a specific exception on failure.\n",
    "        try:\n",
    "            jd_full_text = read_file(jd_path)\n",
    "        except Exception as e:\n",
    "            # This catch block is a safeguard if read_file itself doesn't handle all its exceptions\n",
    "            # or if an unexpected error occurs during the call.\n",
    "            print(f\"ERROR: An error occurred while calling read_file for '{jd_path}': {e}\")\n",
    "            jd_full_text = \"\" # Ensure it's empty on error\n",
    "\n",
    "        # After attempting to read, check if 'jd_full_text' actually contains content.\n",
    "        if jd_full_text and jd_full_text.strip(): # .strip() checks if it's not just whitespace\n",
    "            print(f\"INFO: Successfully read Job Description: '{JOB_DESCRIPTION_FILENAME}'\")\n",
    "            \n",
    "            # Optional: Display a snippet for quick verification in interactive environments (e.g., Jupyter).\n",
    "            # INSPECT_JD_SNIPPET = False # Set to True to enable\n",
    "            # if INSPECT_JD_SNIPPET:\n",
    "            #     print(\"\\n--- Job Description Snippet (first 300 chars) ---\")\n",
    "            #     print(jd_full_text[:300] + \"...\" if len(jd_full_text) > 300 else jd_full_text)\n",
    "            #     print(\"--------------------------------------------------\\n\")\n",
    "        else:\n",
    "            # This condition means 'read_file()' might have returned an empty string (e.g., due to an\n",
    "            # internal error in 'read_file', an unsupported file type if 'read_file' doesn't raise errors,\n",
    "            # or the JD file itself is empty or contains no extractable text).\n",
    "            # This is critical, as a valid JD is essential for the script's operation.\n",
    "            error_message = (f\"CRITICAL ERROR: Job Description file '{jd_path}' was found, \"\n",
    "                             f\"but no text could be extracted, or the file is empty. \"\n",
    "                             f\"Please check the file content and the 'read_file' function.\")\n",
    "            print(error_message)\n",
    "            # In a production script, you might want to raise an exception or exit here:\n",
    "            # raise ValueError(error_message)\n",
    "            # For a notebook, jd_full_text will remain empty, and subsequent cells should check for this.\n",
    "            \n",
    "    else:\n",
    "        # The path exists, but it points to a directory, not a regular file.\n",
    "        error_message = (f\"CRITICAL ERROR: The path specified for the Job Description '{jd_path}' \"\n",
    "                         f\"points to a directory, not a file. Please ensure '{JOB_DESCRIPTION_FILENAME}' \"\n",
    "                         f\"is a file within the '{job_description_folder}' directory.\")\n",
    "        print(error_message)\n",
    "        # raise FileNotFoundError(error_message) # More specific error type\n",
    "else:\n",
    "    # The JD file was not found at the specified path. This is a critical failure.\n",
    "    error_message = (f\"CRITICAL ERROR: Job Description file not found at '{jd_path}'. \"\n",
    "                     f\"Please ensure the file '{JOB_DESCRIPTION_FILENAME}' exists in the \"\n",
    "                     f\"'{job_description_folder}' directory.\")\n",
    "    print(error_message)\n",
    "    # raise FileNotFoundError(error_message)\n",
    "\n",
    "# --- Verification for subsequent cells ---\n",
    "# It's crucial for subsequent cells to check if 'jd_full_text' was successfully populated.\n",
    "# Example check for the start of the next cell:\n",
    "# if not jd_full_text:\n",
    "#     print(\"STOPPING: Cannot proceed without valid Job Description content.\")\n",
    "#     # raise ValueError(\"JD content is missing, cannot continue.\")\n",
    "# else:\n",
    "#     # Proceed with using jd_full_text\n",
    "#     pass\n",
    "\n",
    "# --- End of Job Description Reading Cell ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Looking for sample resumes (for JSON processing) in directory: c:\\Users\\harry\\OneDrive\\Desktop\\AI RESUME SCANNER\\AI_RESUME_SCANNER\\sample_resume\n",
      "INFO: Found 5 potential sample resume file(s): ['Carlos A. Martinez.pdf', 'Emily S. Turner.pdf', 'John R. Williams.pdf', 'Linda J. Park.pdf', 'Michael D. Lee.pdf']\n",
      "\n",
      "INFO: Generating structured JSON for 5 sample resume(s)...\n",
      "INFO: Processing sample 1/5 ('Carlos A. Martinez.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing sample 2/5 ('Emily S. Turner.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing sample 3/5 ('John R. Williams.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing sample 4/5 ('Linda J. Park.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing sample 5/5 ('Michael D. Lee.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Finished generating structured JSON and extracting summaries for sample resumes. 'sample_outputs' now has 5 items.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Process Sample Resumes to Generate Structured JSON and Extract Ideal Match Summaries ---\n",
    "\n",
    "# This cell reads sample resumes, sends them to the OpenAI API with a prompt\n",
    "# instructing the AI to output structured JSON (containing extracted info and an ideal match summary).\n",
    "# The Python code then parses this JSON and extracts the \"ideal_match_summary\" text.\n",
    "# These summaries, stored in 'sample_outputs', will be used for embedding.\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# (Same as your previous version of this cell: sample_folder, jd_full_text, read_file, os, openai, client)\n",
    "# Make sure 'datetime' is imported for 'current_date_for_ai_instruction'.\n",
    "\n",
    "# --- Configuration for OpenAI API Call for Sample Resumes (JSON Output) ---\n",
    "# IMPORTANT: Verify your model ID is valid and accessible.\n",
    "OPENAI_MODEL_FOR_SAMPLES_JSON = \"gpt-4.1-2025-04-14\" # REPLACE with your valid model ID\n",
    "# OPENAI_MODEL_FOR_SAMPLES_JSON = \"gpt-3.5-turbo-0125\" # Alternative for testing\n",
    "\n",
    "OPENAI_TEMPERATURE_FOR_SAMPLES_JSON = 0.2 # Lower temperature for more structured, deterministic JSON.\n",
    "OPENAI_MAX_TOKENS_FOR_SAMPLES_JSON = 1000 # JSON output can be longer; adjust based on typical resume complexity and summary length.\n",
    "                                       # Ensure this + prompt tokens < model's context window.\n",
    "\n",
    "current_date_for_ai_instruction = datetime.date.today().isoformat()\n",
    "\n",
    "# New System Prompt instructing AI to output JSON.\n",
    "# This is the NEW_SYSTEM_MESSAGE_FOR_SAMPLES_JSON_OUTPUT I provided earlier.\n",
    "SYSTEM_MESSAGE_FOR_SAMPLES_JSON = f\"\"\"\n",
    "You are an expert AI assistant specialized in identifying and deconstructing high-quality resumes for the travel industry.\n",
    "You will be provided with a job description (JD) and a sample resume that is considered an EXCELLENT match for that role.\n",
    "Your task is to extract key structured information from this excellent sample resume and then, based on this extracted information and the JD, generate a concise profile summary highlighting why it's an excellent match.\n",
    "\n",
    "Please structure your ENTIRE output as a single, valid JSON object.\n",
    "The JSON object MUST have the following top-level keys: \"extracted_info\", \"ideal_match_summary\".\n",
    "Do NOT include any text outside of this JSON object (no greetings, no explanations, no ```json ... ``` markdown).\n",
    "\n",
    "1.  \"extracted_info\":\n",
    "    * This MUST be a JSON object containing structured details from the sample resume.\n",
    "    * It MUST include keys like:\n",
    "        * \"job_history\": (list of objects, each with \"role\", \"company\", \"start_date\", \"end_date\", \"raw_tenure_text\". Use \"{current_date_for_ai_instruction}\" for current roles' end_date). If no history, use [].\n",
    "        * \"skills\": (list of strings) Key skills listed or inferred that are relevant to the JD.\n",
    "        * \"education\": (list of strings) Relevant education entries.\n",
    "        * \"location_info\": (object, with \"city\", \"state\", \"country\", \"raw_location_text\").\n",
    "        * \"quantifiable_achievements\": (list of strings) Any quantifiable achievements mentioned.\n",
    "    * For date fields (\"start_date\", \"end_date\"), attempt \"YYYY-MM\" or \"YYYY-MM-DD\". If ambiguous, use \"Unknown\".\n",
    "    * If a field within \"extracted_info\" cannot be found, use \"Not Specified\" for strings or null for other types where appropriate, or an empty list [] for lists.\n",
    "\n",
    "2.  \"ideal_match_summary\":\n",
    "    * (string) Based SOLELY on the \"extracted_info\" from this sample resume AND the provided Job Description (JD), generate a concise (target 3-5 sentences, around 250-350 tokens) summary.\n",
    "    * This summary should articulate the CORE reasons and key characteristics that make this specific sample resume an IDEAL benchmark candidate for the JD.\n",
    "    * Focus on the most impactful alignments (e.g., \"Possesses X+ years in luxury travel sales directly matching JD requirements, demonstrated by consistently exceeding targets. Key skills include advanced objection handling and CRM proficiency, vital for this role.\")\n",
    "    * This summary will be the primary text used for generating the 'sample_embedding'.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize lists\n",
    "sample_paths_processed = [] # Store paths of successfully processed samples\n",
    "sample_texts_processed = [] # Store texts of successfully processed samples\n",
    "sample_outputs = []         # THIS WILL NOW STORE THE \"ideal_match_summary\" STRING\n",
    "sample_extracted_json_data = [] # Optional: Store the full parsed JSON from AI for each sample\n",
    "\n",
    "# --- Ensure OpenAI Client is Initialized ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        if not client.api_key: raise openai.AuthenticationError(\"OpenAI API key not found by client.\")\n",
    "        print(\"INFO: OpenAI client (re)initialized successfully for processing samples (JSON output).\")\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Failed to initialize OpenAI client for samples (JSON output). Error: {e}\")\n",
    "        client = None\n",
    "\n",
    "# --- Stage 1: Discover and Read Sample Resume Files ---\n",
    "if client:\n",
    "    print(f\"INFO: Looking for sample resumes (for JSON processing) in directory: {os.path.abspath(sample_folder)}\")\n",
    "    try:\n",
    "        found_sample_files = [f for f in os.listdir(sample_folder) if f.lower().endswith((\".pdf\", \".docx\"))]\n",
    "        \n",
    "        if not found_sample_files:\n",
    "            print(f\"WARNING: No .pdf or .docx sample resumes found in '{sample_folder}'.\")\n",
    "        else:\n",
    "            all_initial_sample_paths = [os.path.join(sample_folder, filename) for filename in found_sample_files]\n",
    "            print(f\"INFO: Found {len(all_initial_sample_paths)} potential sample resume file(s): {found_sample_files}\")\n",
    "\n",
    "            temp_texts_for_json_processing = []\n",
    "            valid_paths_for_json_processing_samples = []\n",
    "\n",
    "            for path_to_file in all_initial_sample_paths:\n",
    "                text_content = read_file(path_to_file)\n",
    "                if text_content and text_content.strip():\n",
    "                    temp_texts_for_json_processing.append(text_content)\n",
    "                    valid_paths_for_json_processing_samples.append(path_to_file)\n",
    "                else:\n",
    "                    print(f\"WARNING: Skipped (no text): {os.path.basename(path_to_file)} for JSON processing.\")\n",
    "            \n",
    "            sample_texts_processed = temp_texts_for_json_processing\n",
    "            sample_paths_processed = valid_paths_for_json_processing_samples\n",
    "\n",
    "            if not sample_texts_processed:\n",
    "                print(f\"WARNING: No text extracted from any sample files. 'sample_outputs' will be empty.\")\n",
    "            else:\n",
    "                # --- Stage 2: Generate Structured JSON and Extract Ideal Match Summary for Samples ---\n",
    "                print(f\"\\nINFO: Generating structured JSON for {len(sample_texts_processed)} sample resume(s)...\")\n",
    "                \n",
    "                for i, individual_sample_text in enumerate(sample_texts_processed):\n",
    "                    current_sample_file = os.path.basename(sample_paths_processed[i])\n",
    "                    print(f\"INFO: Processing sample {i+1}/{len(sample_texts_processed)} ('{current_sample_file}') with OpenAI model '{OPENAI_MODEL_FOR_SAMPLES_JSON}' for JSON output...\")\n",
    "                    \n",
    "                    ai_response_json_str = None\n",
    "                    parsed_json_output = None\n",
    "                    ideal_summary_for_embedding = \"\" # Default to empty string\n",
    "\n",
    "                    try:\n",
    "                        response = client.chat.completions.create(\n",
    "                            model=OPENAI_MODEL_FOR_SAMPLES_JSON,\n",
    "                            messages=[\n",
    "                                {\"role\": \"system\", \"content\": SYSTEM_MESSAGE_FOR_SAMPLES_JSON},\n",
    "                                {\"role\": \"user\", \"content\": f\"JOB DESCRIPTION:\\n```\\n{jd_full_text}\\n```\"},\n",
    "                                {\"role\": \"user\", \"content\": f\"SAMPLE RESUME TEXT TO ANALYZE AND STRUCTURE:\\n```\\n{individual_sample_text}\\n```\"}\n",
    "                            ],\n",
    "                            temperature=OPENAI_TEMPERATURE_FOR_SAMPLES_JSON,\n",
    "                            max_tokens=OPENAI_MAX_TOKENS_FOR_SAMPLES_JSON,\n",
    "                            # response_format={ \"type\": \"json_object\" } # For newer models that support strict JSON mode\n",
    "                        )\n",
    "                        ai_response_json_str = response.choices[0].message.content.strip()\n",
    "                        \n",
    "                        # Attempt to parse the JSON string\n",
    "                        try:\n",
    "                            # Sometimes AI might wrap output in ```json ... ```, try to strip it if present\n",
    "                            if ai_response_json_str.startswith(\"```json\"):\n",
    "                                ai_response_json_str = ai_response_json_str[7:]\n",
    "                                if ai_response_json_str.endswith(\"```\"):\n",
    "                                    ai_response_json_str = ai_response_json_str[:-3]\n",
    "                            ai_response_json_str = ai_response_json_str.strip() # Ensure no leading/trailing whitespace\n",
    "\n",
    "                            parsed_json_output = json.loads(ai_response_json_str)\n",
    "                            ideal_summary_for_embedding = parsed_json_output.get(\"ideal_match_summary\", \"\").strip()\n",
    "                            if not ideal_summary_for_embedding:\n",
    "                                print(f\"WARNING: AI returned JSON for '{current_sample_file}', but 'ideal_match_summary' was empty or missing.\")\n",
    "                                ideal_summary_for_embedding = f\"Error extracting ideal_match_summary for {current_sample_file}\" # Placeholder\n",
    "                            \n",
    "                            sample_extracted_json_data.append(parsed_json_output) # Optional: store full JSON\n",
    "\n",
    "                        except json.JSONDecodeError as je:\n",
    "                            print(f\"ERROR (JSON Decode): Failed to parse AI's JSON response for sample '{current_sample_file}'. Error: {je}\")\n",
    "                            print(f\"AI Raw Response was: {ai_response_json_str}\")\n",
    "                            ideal_summary_for_embedding = f\"Error parsing JSON for {current_sample_file}\" # Placeholder\n",
    "                        except Exception as e_parse: # Catch other errors during parsing or key access\n",
    "                            print(f\"ERROR (Post-JSON Parse): Error processing parsed JSON for sample '{current_sample_file}'. Error: {e_parse}\")\n",
    "                            ideal_summary_for_embedding = f\"Error processing parsed JSON for {current_sample_file}\" # Placeholder\n",
    "\n",
    "                    # Error Handling for OpenAI API call itself (copied from previous, ensure it's up-to-date)\n",
    "                    except openai.APIConnectionError as e:\n",
    "                        print(f\"ERROR (API Connection) for sample '{current_sample_file}': {e}\")\n",
    "                        ideal_summary_for_embedding = f\"API_CONNECTION_ERROR_SAMPLE_JSON: {e}\"\n",
    "                    # ... (include other specific openai errors: RateLimitError, AuthenticationError, NotFoundError, APIStatusError) ...\n",
    "                    except openai.RateLimitError as e:\n",
    "                        print(f\"ERROR (Rate Limit / Quota): For sample '{current_sample_file}': {e}\")\n",
    "                        ideal_summary_for_embedding = f\"API_RATE_LIMIT_ERROR_SAMPLE_JSON: {e}\"\n",
    "                    except openai.AuthenticationError as e:\n",
    "                        print(f\"ERROR (Authentication): For sample '{current_sample_file}': {e}\")\n",
    "                        ideal_summary_for_embedding = f\"API_AUTHENTICATION_ERROR_SAMPLE_JSON: {e}\"\n",
    "                    except openai.NotFoundError as e: \n",
    "                        print(f\"ERROR (Not Found - e.g., Model ID): For sample '{current_sample_file}': {e}\")\n",
    "                        ideal_summary_for_embedding = f\"API_NOT_FOUND_ERROR_SAMPLE_JSON: Model '{OPENAI_MODEL_FOR_SAMPLES_JSON}'?\"\n",
    "                    except openai.APIStatusError as e: \n",
    "                        error_msg_detail = str(e)\n",
    "                        try: error_msg_detail = e.response.json().get('error', {}).get('message', str(e))\n",
    "                        except: pass\n",
    "                        print(f\"ERROR (API Status): For sample '{current_sample_file}': HTTP Status {e.status_code}, Msg: {error_msg_detail}\")\n",
    "                        ideal_summary_for_embedding = f\"API_STATUS_ERROR_SAMPLE_JSON: HTTP {e.status_code}\"\n",
    "                    except Exception as e: \n",
    "                        print(f\"ERROR (Unexpected) calling OpenAI for sample '{current_sample_file}': {type(e).__name__} - {e}\")\n",
    "                        ideal_summary_for_embedding = f\"UNEXPECTED_PROCESSING_ERROR_SAMPLE_JSON: {e}\"\n",
    "                    \n",
    "                    sample_outputs.append(ideal_summary_for_embedding) # This now stores the extracted summary or an error string.\n",
    "                \n",
    "                print(f\"INFO: Finished generating structured JSON and extracting summaries for sample resumes. 'sample_outputs' now has {len(sample_outputs)} items.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"CRITICAL ERROR: 'sample_folder' ({os.path.abspath(sample_folder)}) not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Unexpected error during sample file discovery/reading: {type(e).__name__} - {e}\")\n",
    "else:\n",
    "    print(\"CRITICAL ERROR: OpenAI client not initialized. Skipping processing of sample resumes for JSON output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extracted 'ideal_match_summary' for Sample Resumes (5 total) ---\n",
      "\n",
      "For Sample File: Carlos A. Martinez.pdf (Sample 1/5)\n",
      "Extracted Ideal Match Summary:\n",
      "Carlos A. Martinez is an exemplary fit for the Inbound Sales Consultant role at ABC Cruises, bringing over 8 years of luxury travel sales experience with a proven track record in remote, phone-based closing. His tenure includes consistently ranking #1 for customer conversion and upsell, closing more than 500 bookings, and developing sales scripts that increased close rates by 17%—demonstrating mastery in objection handling and exceeding sales KPIs, both of which are core requirements in the JD. Carlos’s expertise in CRM systems, pipeline management, and post-sale follow-up aligns perfectly with the need for accurate record-keeping and relationship building with high-end clients. His bilingual proficiency (English and Spanish) and background in hospitality management further enhance his ability to deliver personalized, high-touch service to a diverse and discerning clientele. Based in Miami, FL, Carlos is well-positioned for a remote, US-based role and has demonstrated the discipline, motivation, and technical proficiency necessary for success in a structured virtual sales environment.\n",
      "----------------------------------------\n",
      "\n",
      "For Sample File: Emily S. Turner.pdf (Sample 2/5)\n",
      "Extracted Ideal Match Summary:\n",
      "Emily S. Turner is an outstanding fit for the Inbound Sales Consultant role at ABC Cruises, bringing over 7 years of high-volume B2C phone sales experience within the luxury travel sector. Her proven track record includes consistently exceeding sales KPIs, such as converting over 30% of inbound leads to bookings, surpassing monthly call targets by 18%, and generating $2.5M in new revenue through referral networks. Emily excels in remote sales environments, demonstrates advanced skills in objection handling, CRM utilization (Salesforce), and relationship building—key requirements for the role. Her history of delivering top client satisfaction (4.9/5 average feedback) and her expertise in closing sales on the first call directly align with ABC Cruises’ focus on high-net-worth guests and exceptional service. Based in Dallas, TX, Emily is well-positioned to thrive in a fully virtual, structured environment, making her an ideal benchmark candidate for this position.\n",
      "----------------------------------------\n",
      "\n",
      "For Sample File: John R. Williams.pdf (Sample 3/5)\n",
      "Extracted Ideal Match Summary:\n",
      "John R. Williams is an exemplary candidate for the remote Inbound Sales Consultant role at ABC Cruises, offering over 8 years of high-volume B2C phone sales experience in the luxury travel sector. His proven track record includes consistently exceeding sales quotas, with achievements such as closing 170+ travel packages in a single year at a 32% conversion rate and ranking in the top 5% of national sales. John demonstrates advanced skills in consultative selling, objection handling, and CRM-driven pipeline management—directly aligning with the JD's requirements for closing sales, building client relationships, and maintaining accurate records. His experience with both inbound and outbound sales, repeat customer growth, and training new hires in advanced sales techniques further highlights his ability to thrive in a structured, remote environment. Additionally, his technical proficiency with Salesforce, HubSpot, and MS Office ensures he can seamlessly adapt to ABC Cruises' virtual sales operations, making him an ideal benchmark for this position.\n",
      "----------------------------------------\n",
      "\n",
      "For Sample File: Linda J. Park.pdf (Sample 4/5)\n",
      "Extracted Ideal Match Summary:\n",
      "Linda J. Park is an exemplary fit for the Inbound Sales Consultant role at ABC Cruises, bringing over 10 years of luxury travel sales experience with a proven track record of high-volume phone sales and quota overachievement. Her background includes managing and coaching remote sales teams, consistently exceeding sales goals by 25–40% annually, and personally closing 400+ phone sales in three years—demonstrating mastery in objection handling, first-call closing, and relationship building with high-end clients. Linda’s expertise in CRM and pipeline management, along with her proficiency in MS Office, directly aligns with the technical requirements of the role. Her quantifiable achievements, such as raising team quotas to 130% and ranking in the top 3% nationwide, underscore her drive, discipline, and ability to thrive in a structured, virtual environment. Based in the USA and experienced in remote work, Linda embodies the entrepreneurial spirit, ethical standards, and passion for curating extraordinary travel experiences that ABC Cruises seeks.\n",
      "----------------------------------------\n",
      "\n",
      "For Sample File: Michael D. Lee.pdf (Sample 5/5)\n",
      "Extracted Ideal Match Summary:\n",
      "Michael D. Lee is an exemplary candidate for the remote Inbound Sales Consultant role at ABC Cruises, bringing over 9 years of high-volume phone sales experience in the travel industry. His proven track record includes consistently exceeding quotas (over 140% attainment), closing 10+ phone sales per week, and maintaining a robust pipeline of 500+ prospects, directly aligning with the JD’s emphasis on sales performance and KPI outperformance. Michael’s expertise in consultative closing, advanced objection handling, and CRM management (HubSpot, Salesforce, MS Office) ensures he can deliver personalized recommendations and close sales efficiently, including on the first call. His experience with high-end travel bookings and client retention demonstrates his ability to build lasting relationships with discerning guests, while his remote work background and technical proficiency make him well-suited for a structured, virtual environment. Overall, Michael’s quantifiable achievements, industry-specific sales acumen, and customer-centric approach make him an ideal benchmark for this role.\n",
      "----------------------------------------\n",
      "--- End of Sample Summaries Inspection ---\n"
     ]
    }
   ],
   "source": [
    "# --- Optional: Verification (Adjust to show extracted summaries) ---\n",
    "INSPECT_EXTRACTED_SAMPLE_SUMMARIES = True # Set to True to print.\n",
    "\n",
    "if INSPECT_EXTRACTED_SAMPLE_SUMMARIES and sample_outputs:\n",
    "    print(f\"\\n--- Extracted 'ideal_match_summary' for Sample Resumes ({len(sample_outputs)} total) ---\")\n",
    "    for i, summary_text in enumerate(sample_outputs):\n",
    "        original_filename = os.path.basename(sample_paths_processed[i]) if i < len(sample_paths_processed) else \"Unknown Original\"\n",
    "        print(f\"\\nFor Sample File: {original_filename} (Sample {i+1}/{len(sample_outputs)})\")\n",
    "        if \"ERROR\" in summary_text or not summary_text.strip():\n",
    "            print(f\"   [AI Processing resulted in an error/placeholder or empty summary]: {summary_text}\")\n",
    "        else:\n",
    "            print(f\"Extracted Ideal Match Summary:\\n{summary_text}\")\n",
    "        print(\"-\" * 40)\n",
    "    print(\"--- End of Sample Summaries Inspection ---\")\n",
    "elif INSPECT_EXTRACTED_SAMPLE_SUMMARIES:\n",
    "    print(\"\\nINFO: 'sample_outputs' is empty or inspection is disabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Looking for candidate resumes (for JSON processing) in directory: c:\\Users\\harry\\OneDrive\\Desktop\\AI RESUME SCANNER\\AI_RESUME_SCANNER\\original_resume\n",
      "INFO: Found 21 potential candidate resume file(s): ['Alexandra N. White.pdf', 'Amanda B. Chen.pdf', 'Brian J. Walker.pdf', 'Chloe R. Johnson.pdf', 'Christopher N. Patel.pdf', 'David S. King.pdf', 'Derek J. Nelson.pdf', 'Elena R. Castillo.pdf', 'Jason T. Kim.pdf', 'Jessica L. Morgan.pdf', 'Kevin J. Stone.pdf', 'Lauren K. Smith.pdf', 'Mark L. Thompson.pdf', 'Morgan L. Wright.pdf', 'Omar S. Farouk.pdf', 'Rebecca D. Miller.pdf', 'Samantha Q. Evans.pdf', 'Samuel D. Reed.pdf', 'Sophia E. Lopez.pdf', 'Tyler M. Harris.pdf', 'Wei Lin.pdf']\n",
      "\n",
      "INFO: Generating structured JSON for 21 candidate resume(s)...\n",
      "INFO: Processing candidate 1/21 ('Alexandra N. White.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 2/21 ('Amanda B. Chen.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 3/21 ('Brian J. Walker.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 4/21 ('Chloe R. Johnson.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 5/21 ('Christopher N. Patel.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 6/21 ('David S. King.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 7/21 ('Derek J. Nelson.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 8/21 ('Elena R. Castillo.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 9/21 ('Jason T. Kim.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 10/21 ('Jessica L. Morgan.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 11/21 ('Kevin J. Stone.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 12/21 ('Lauren K. Smith.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 13/21 ('Mark L. Thompson.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 14/21 ('Morgan L. Wright.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 15/21 ('Omar S. Farouk.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 16/21 ('Rebecca D. Miller.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 17/21 ('Samantha Q. Evans.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 18/21 ('Samuel D. Reed.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 19/21 ('Sophia E. Lopez.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 20/21 ('Tyler M. Harris.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Processing candidate 21/21 ('Wei Lin.pdf') with OpenAI model 'gpt-4.1-2025-04-14' for JSON output...\n",
      "INFO: Finished generating raw JSON outputs for candidate resumes. 'raw_ai_json_outputs_for_candidates' now has 21 items.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Process Candidate Resumes for Structured Info Extraction and Preliminary Analysis (JSON Output) ---\n",
    "\n",
    "# This cell reads candidate resumes from 'original_resumes_folder'.\n",
    "# For each resume, it calls the OpenAI API with a specific system message ('NEW_SYSTEM_MESSAGE_FOR_CANDIDATES')\n",
    "# that instructs the AI to output a structured JSON object containing:\n",
    "#   1. Extracted job history (for Python-based tenure calculation).\n",
    "#   2. Extracted location information (for Python-based location check).\n",
    "#   3. A brief qualitative JD alignment summary (this will be used for embedding if rules pass).\n",
    "# The Python code in *subsequent cells* will parse this JSON, perform rule-based filtering\n",
    "# (tenure, location), and then prepare the 'jd_alignment_summary' for embedding.\n",
    "# This cell's primary output is 'raw_ai_json_outputs_for_candidates' (list of JSON strings or error markers)\n",
    "# and a synchronized 'candidate_paths_for_processing' list.\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# Expected variables from previous cells:\n",
    "#   - 'original_resumes_folder': Path to the directory containing candidate resumes.\n",
    "#   - 'jd_full_text': String containing the full text of the job description.\n",
    "#   - 'read_file': Function to extract text from .pdf and .docx files.\n",
    "#   - 'os', 'openai', 'datetime', 'json' modules imported.\n",
    "#   - 'client': An initialized OpenAI client object for SDK v1.x.x.\n",
    "\n",
    "# --- Configuration for OpenAI API Call for Candidate Resumes (JSON Output) ---\n",
    "# IMPORTANT: Verify your model ID is valid and accessible.\n",
    "OPENAI_MODEL_FOR_CANDIDATES_JSON = \"gpt-4.1-2025-04-14\" # REPLACE with your valid and accessible model ID\n",
    "# OPENAI_MODEL_FOR_CANDIDATES_JSON = \"gpt-3.5-turbo-0125\" # Alternative for testing\n",
    "\n",
    "OPENAI_TEMPERATURE_FOR_CANDIDATES_JSON = 0.1 # Very low temperature for structured, factual JSON output.\n",
    "OPENAI_MAX_TOKENS_FOR_CANDIDATES_JSON = 1500 # JSON output can be quite long for detailed resumes.\n",
    "                                           # Adjust based on typical resume complexity and model context window.\n",
    "                                           # Ensure this + prompt tokens < model's context window.\n",
    "\n",
    "current_date_for_ai_instruction = datetime.date.today().isoformat()\n",
    "\n",
    "# System Prompt instructing AI to output structured JSON for candidate resumes.\n",
    "# This is the 'NEW_SYSTEM_MESSAGE_FOR_CANDIDATES' prompt discussed previously.\n",
    "SYSTEM_MESSAGE_FOR_CANDIDATES_JSON = f\"\"\"\n",
    "You are an expert AI assistant specialized in meticulous resume data extraction and preliminary analysis for the travel industry.\n",
    "You will be provided with a job description (JD) and a candidate's resume text.\n",
    "Your task is to extract specific pieces of information from the resume and provide a brief qualitative summary based on the JD.\n",
    "\n",
    "Please structure your ENTIRE output as a single, valid JSON object.\n",
    "The JSON object MUST have the following top-level keys: \"job_history\", \"location_info\", \"jd_alignment_summary\".\n",
    "Do NOT include any text outside of this JSON object (no greetings, no explanations, no ```json ... ``` markdown).\n",
    "\n",
    "1.  \"job_history\":\n",
    "    * This MUST be a list of JSON objects (dictionaries).\n",
    "    * For each distinct job position you can identify in the resume, create one JSON object.\n",
    "    * Each job object MUST contain the following keys:\n",
    "        * \"role\": (string) The job title or role as stated in the resume. If not found, use \"Not Specified\".\n",
    "        * \"company\": (string) The company name as stated. If not found, use \"Not Specified\".\n",
    "        * \"start_date\": (string) The start date of the role. Attempt to parse and provide in \"YYYY-MM\" format (e.g., \"2019-03\"). If only year is available, use \"YYYY\" (e.g., \"2019\"). If a more precise date like \"YYYY-MM-DD\" is clearly stated, use that. If a start date cannot be reliably determined, use \"Unknown\".\n",
    "        * \"end_date\": (string) The end date of the role, following the same formatting rules as \"start_date\". If the role is clearly stated as current (e.g., \"Present\", \"Current\", \"To Date\", \"Now\"), use the exact string \"{current_date_for_ai_instruction}\" for this field. If an end date cannot be reliably determined, use \"Unknown\".\n",
    "        * \"raw_tenure_text\": (string) The exact, verbatim text snippet from the resume that describes the dates or tenure for this specific role (e.g., \"Jan 2020 - Present\", \"2018 to 2019\", \"3 years relevant experience\"). If no such snippet is found for a role, use \"Not Specified\".\n",
    "    * If no job history is found or discernible, \"job_history\" should be an empty list: [].\n",
    "\n",
    "2.  \"location_info\":\n",
    "    * This MUST be a JSON object (dictionary).\n",
    "    * It MUST contain the following keys:\n",
    "        * \"city\": (string or null) The candidate's primary city, if discernible from contact information or summary. If not found, use null.\n",
    "        * \"state\": (string or null) The candidate's state or province, if discernible. If not found, use null.\n",
    "        * \"country\": (string or null) The candidate's country. Attempt to determine if it is \"USA\". If clearly another country, state that country name. If ambiguous or not found, use null.\n",
    "        * \"raw_location_text\": (string) The verbatim text snippet from the resume where primary location information was found. If not found, use \"Not Specified\".\n",
    "\n",
    "3.  \"jd_alignment_summary\":\n",
    "    * (string) Based on the provided Job Description (JD), provide a VERY BRIEF qualitative summary (strictly 1 to 3 sentences, target around 50-100 words) indicating the overall apparent alignment of the candidate's skills and experiences with the JD.\n",
    "    * Focus on key aspects such as relevant industry experience, core skills mentioned in the JD, and overall suitability from a quick review.\n",
    "    * If the resume seems completely irrelevant to the JD based on a high-level assessment, state that clearly and briefly.\n",
    "    * Avoid making definitive hiring decisions; this is a preliminary alignment assessment. This summary will be used for further semantic matching if other criteria are met.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize lists\n",
    "candidate_paths_for_processing = [] # Stores paths of successfully read candidate resumes.\n",
    "candidate_texts_for_processing = [] # Stores text of successfully read candidate resumes.\n",
    "# This list will store the RAW JSON strings (or error markers) returned by the AI for each candidate.\n",
    "# Parsing and rule-based filtering will happen in a SUBSEQUENT cell.\n",
    "raw_ai_json_outputs_for_candidates = [] \n",
    "\n",
    "# --- Ensure OpenAI Client is Initialized ---\n",
    "if 'client' not in locals() or client is None:\n",
    "    try:\n",
    "        client = openai.OpenAI()\n",
    "        if not client.api_key: raise openai.AuthenticationError(\"OpenAI API key not found by client.\")\n",
    "        print(\"INFO: OpenAI client (re)initialized successfully for processing candidate resumes (JSON output).\")\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Failed to initialize OpenAI client for candidate resumes (JSON output). Error: {e}\")\n",
    "        client = None\n",
    "\n",
    "# --- Stage 1: Discover and Read Candidate Resume Files ---\n",
    "if client:\n",
    "    print(f\"INFO: Looking for candidate resumes (for JSON processing) in directory: {os.path.abspath(original_resumes_folder)}\")\n",
    "    try:\n",
    "        found_candidate_files_list = [f for f in os.listdir(original_resumes_folder) if f.lower().endswith((\".pdf\", \".docx\"))]\n",
    "        \n",
    "        if not found_candidate_files_list:\n",
    "            print(f\"WARNING: No .pdf or .docx candidate resumes found in '{original_resumes_folder}'.\")\n",
    "        else:\n",
    "            all_initial_candidate_paths = [os.path.join(original_resumes_folder, filename) for filename in found_candidate_files_list]\n",
    "            print(f\"INFO: Found {len(all_initial_candidate_paths)} potential candidate resume file(s): {found_candidate_files_list}\")\n",
    "\n",
    "            temp_texts_from_candidates = []\n",
    "            valid_paths_for_candidate_processing = []\n",
    "\n",
    "            for path_to_candidate_file in all_initial_candidate_paths:\n",
    "                text_content = read_file(path_to_candidate_file)\n",
    "                if text_content and text_content.strip():\n",
    "                    temp_texts_from_candidates.append(text_content)\n",
    "                    valid_paths_for_candidate_processing.append(path_to_candidate_file)\n",
    "                else:\n",
    "                    print(f\"WARNING: Skipped (no text): {os.path.basename(path_to_candidate_file)} for candidate JSON processing.\")\n",
    "            \n",
    "            candidate_texts_for_processing = temp_texts_from_candidates\n",
    "            candidate_paths_for_processing = valid_paths_for_candidate_processing\n",
    "\n",
    "            if not candidate_texts_for_processing:\n",
    "                print(f\"WARNING: No text extracted from any candidate files. 'raw_ai_json_outputs_for_candidates' will be empty.\")\n",
    "            else:\n",
    "                # --- Stage 2: Generate Structured JSON for Successfully Read Candidate Resumes ---\n",
    "                print(f\"\\nINFO: Generating structured JSON for {len(candidate_texts_for_processing)} candidate resume(s)...\")\n",
    "                \n",
    "                for i, individual_candidate_text in enumerate(candidate_texts_for_processing):\n",
    "                    current_candidate_file = os.path.basename(candidate_paths_for_processing[i])\n",
    "                    print(f\"INFO: Processing candidate {i+1}/{len(candidate_texts_for_processing)} ('{current_candidate_file}') with OpenAI model '{OPENAI_MODEL_FOR_CANDIDATES_JSON}' for JSON output...\")\n",
    "                    \n",
    "                    ai_response_str_for_candidate = f\"ERROR_AI_CALL_NOT_ATTEMPTED_FOR_{current_candidate_file}\" # Default error\n",
    "                    try:\n",
    "                        response = client.chat.completions.create(\n",
    "                            model=OPENAI_MODEL_FOR_CANDIDATES_JSON,\n",
    "                            messages=[\n",
    "                                {\"role\": \"system\", \"content\": SYSTEM_MESSAGE_FOR_CANDIDATES_JSON},\n",
    "                                {\"role\": \"user\", \"content\": f\"JOB DESCRIPTION:\\n```\\n{jd_full_text}\\n```\"},\n",
    "                                {\"role\": \"user\", \"content\": f\"CANDIDATE RESUME TEXT TO ANALYZE AND STRUCTURE:\\n```\\n{individual_candidate_text}\\n```\"}\n",
    "                            ],\n",
    "                            temperature=OPENAI_TEMPERATURE_FOR_CANDIDATES_JSON,\n",
    "                            max_tokens=OPENAI_MAX_TOKENS_FOR_CANDIDATES_JSON,\n",
    "                            # response_format={ \"type\": \"json_object\" } # Add this if your model version supports strict JSON mode\n",
    "                            # timeout=60 # Optional: Longer timeout for complex JSON generation\n",
    "                        )\n",
    "                        ai_response_str_for_candidate = response.choices[0].message.content.strip()\n",
    "                        # Basic check if the response looks like JSON (starts with { ends with })\n",
    "                        # More robust JSON validation will happen in the next cell during parsing.\n",
    "                        if not (ai_response_str_for_candidate.startswith(\"{\") and ai_response_str_for_candidate.endswith(\"}\")):\n",
    "                            print(f\"WARNING: AI response for '{current_candidate_file}' does not look like a JSON object. Raw response: {ai_response_str_for_candidate[:200]}...\")\n",
    "                            # Still append it, parsing errors will be handled in the next cell.\n",
    "                    \n",
    "                    # Error Handling for OpenAI API call\n",
    "                    except openai.APIConnectionError as e:\n",
    "                        print(f\"ERROR (API Connection) for candidate '{current_candidate_file}': {e}\")\n",
    "                        ai_response_str_for_candidate = f\"API_CONNECTION_ERROR_CANDIDATE: {e}\"\n",
    "                    except openai.RateLimitError as e:\n",
    "                        print(f\"ERROR (Rate Limit/Quota) for candidate '{current_candidate_file}': {e}\")\n",
    "                        ai_response_str_for_candidate = f\"API_RATE_LIMIT_ERROR_CANDIDATE: {e}\"\n",
    "                    except openai.AuthenticationError as e:\n",
    "                        print(f\"ERROR (Authentication) for candidate '{current_candidate_file}': {e}\")\n",
    "                        ai_response_str_for_candidate = f\"API_AUTHENTICATION_ERROR_CANDIDATE: {e}\"\n",
    "                    except openai.NotFoundError as e: \n",
    "                        print(f\"ERROR (Not Found - e.g., Model ID) for candidate '{current_candidate_file}': {e}\")\n",
    "                        ai_response_str_for_candidate = f\"API_NOT_FOUND_ERROR_CANDIDATE: Model '{OPENAI_MODEL_FOR_CANDIDATES_JSON}'?\"\n",
    "                    except openai.APIStatusError as e: \n",
    "                        error_msg_detail = str(e)\n",
    "                        try: error_msg_detail = e.response.json().get('error', {}).get('message', str(e))\n",
    "                        except: pass\n",
    "                        print(f\"ERROR (API Status) for candidate '{current_candidate_file}': HTTP Status {e.status_code}, Msg: {error_msg_detail}\")\n",
    "                        ai_response_str_for_candidate = f\"API_STATUS_ERROR_CANDIDATE: HTTP {e.status_code}\"\n",
    "                    except Exception as e: \n",
    "                        print(f\"ERROR (Unexpected) calling OpenAI for candidate '{current_candidate_file}': {type(e).__name__} - {e}\")\n",
    "                        ai_response_str_for_candidate = f\"UNEXPECTED_PROCESSING_ERROR_CANDIDATE: {e}\"\n",
    "                    \n",
    "                    raw_ai_json_outputs_for_candidates.append(ai_response_str_for_candidate)\n",
    "                \n",
    "                print(f\"INFO: Finished generating raw JSON outputs for candidate resumes. 'raw_ai_json_outputs_for_candidates' now has {len(raw_ai_json_outputs_for_candidates)} items.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"CRITICAL ERROR: 'original_resumes_folder' ({os.path.abspath(original_resumes_folder)}) not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"CRITICAL ERROR: Unexpected error during candidate file discovery/reading: {type(e).__name__} - {e}\")\n",
    "else:\n",
    "    print(\"CRITICAL ERROR: OpenAI client not initialized. Skipping processing of candidate resumes for JSON output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Raw AI JSON Outputs for Candidate Resumes (21 total) ---\n",
      "\n",
      "For Candidate File: Alexandra N. White.pdf (Candidate 1/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Sales Consultant\",\n",
      "      \"company\": \"Vista Dream Vacations\",\n",
      "      \"start_date\": \"2019-01\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Jan 2019 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Sales Coordinator\",\n",
      "      \"company\": \"Sunrise Luxury Travel\",\n",
      "      \"start_date\": \"2016-06\",\n",
      "      \"end_date\": \"2018-12\",\n",
      "      \"raw_tenure_text\": \"Jun 2016 – Dec 2018\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Charlotte\",\n",
      "    \"state\": \"NC\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Charlotte, NC\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate demonstrates over 6 years of remote travel sales experience, including direct sales, KPI achievement, and pipeline management in the travel industry. Their background in high-volume sales, objection handling, and client retention aligns closely with the requirements for the Inbound Sales Consultant role at ABC Cruises. Experience with CRM systems and a proven track record of exceeding sales targets further support their suitability for this position.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Amanda B. Chen.pdf (Candidate 2/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Sales Consultant\",\n",
      "      \"company\": \"Luxe Jewelers\",\n",
      "      \"start_date\": \"2017-09\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Sep 2017 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Sales Associate\",\n",
      "      \"company\": \"Gemstone Gallery\",\n",
      "      \"start_date\": \"2015-06\",\n",
      "      \"end_date\": \"2017-08\",\n",
      "      \"raw_tenure_text\": \"Jun 2015 – Aug 2017\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"San Francisco\",\n",
      "    \"state\": \"CA\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"San Francisco, CA\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has over 8 years of high-end sales experience, primarily in luxury retail, with a strong track record in phone-based consultative selling, relationship management, and meeting sales targets. While there is no direct travel industry or cruise sales experience, the skills in handling high-value clients, closing sales over the phone, and CRM usage align well with the core requirements of the Inbound Sales Consultant role. The candidate appears well-suited for a transition into luxury travel sales, though direct industry experience is lacking.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Brian J. Walker.pdf (Candidate 3/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Inside Sales Representative\",\n",
      "      \"company\": \"Signature Realty\",\n",
      "      \"start_date\": \"2018-02\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Feb 2018 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Sales Coordinator\",\n",
      "      \"company\": \"Prestige Properties\",\n",
      "      \"start_date\": \"2016-07\",\n",
      "      \"end_date\": \"2018-01\",\n",
      "      \"raw_tenure_text\": \"Jul 2016 – Jan 2018\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Orlando\",\n",
      "    \"state\": \"FL\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Orlando, FL\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has over 6 years of inside sales experience, primarily in high-ticket real estate, with a strong track record in phone-based prospecting, objection handling, and exceeding sales targets. While there is no direct travel or cruise industry experience, the core sales skills, experience with high-end clients, and proficiency in CRM and phone sales align well with the requirements for the Inbound Sales Consultant role at ABC Cruises.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Chloe R. Johnson.pdf (Candidate 4/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Administrative Assistant\",\n",
      "      \"company\": \"Pinnacle Consulting\",\n",
      "      \"start_date\": \"2018-04\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Apr 2018 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Receptionist\",\n",
      "      \"company\": \"WestEnd Legal\",\n",
      "      \"start_date\": \"2016-05\",\n",
      "      \"end_date\": \"2018-03\",\n",
      "      \"raw_tenure_text\": \"May 2016 – Mar 2018\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Salt Lake City\",\n",
      "    \"state\": \"UT\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Salt Lake City, UT\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has strong administrative and client communication experience but lacks direct sales or telephone sales roles as required by the JD. While organized and skilled in customer follow-up, there is no evidence of sales KPIs, closing sales, or experience with high-end travel clients. Overall, alignment with the travel sales consultant role is limited.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Christopher N. Patel.pdf (Candidate 5/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Sales Advisor\",\n",
      "      \"company\": \"Lone Star Motors\",\n",
      "      \"start_date\": \"2017-03\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Mar 2017 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Sales Associate\",\n",
      "      \"company\": \"Metro Auto Group\",\n",
      "      \"start_date\": \"2014-07\",\n",
      "      \"end_date\": \"2017-02\",\n",
      "      \"raw_tenure_text\": \"Jul 2014 – Feb 2017\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Dallas\",\n",
      "    \"state\": \"TX\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Dallas, TX\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has over 7 years of phone-based sales experience, consistently exceeding targets and demonstrating strong skills in lead qualification, deal closing, and CRM management. While their background is in automotive sales rather than travel, their expertise in high-value negotiations and phone sales aligns well with the core requirements of the Inbound Sales Consultant role. No direct travel industry experience is evident, but the candidate appears well-suited for a transition into cruise sales given their sales track record.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: David S. King.pdf (Candidate 6/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Senior Travel Sales Associate\",\n",
      "      \"company\": \"Epic Getaways\",\n",
      "      \"start_date\": \"2018-05\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"May 2018 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Sales Agent\",\n",
      "      \"company\": \"Platinum Travel Service\",\n",
      "      \"start_date\": \"2014-08\",\n",
      "      \"end_date\": \"2018-04\",\n",
      "      \"raw_tenure_text\": \"Aug 2014 – Apr 2018\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Las Vegas\",\n",
      "    \"state\": \"NV\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Las Vegas, NV\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate demonstrates strong alignment with the JD, offering over 9 years of B2C phone sales experience in the travel industry, a proven record of closing sales, upselling premium travel products, and managing VIP clients. Their remote work experience, KPI-driven approach, and technical proficiency in MS Office further support suitability for the Inbound Sales Consultant role at ABC Cruises. Overall, the candidate appears highly relevant and well-matched to the position requirements.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Derek J. Nelson.pdf (Candidate 7/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Customer Service Representative\",\n",
      "      \"company\": \"National Utilities\",\n",
      "      \"start_date\": \"2020-02\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Feb 2020 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Help Desk Associate\",\n",
      "      \"company\": \"TechAssist STL\",\n",
      "      \"start_date\": \"2018-07\",\n",
      "      \"end_date\": \"2020-01\",\n",
      "      \"raw_tenure_text\": \"Jul 2018 – Jan 2020\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"St. Louis\",\n",
      "    \"state\": \"MO\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"St. Louis, MO\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has solid inbound call center experience and strong customer service skills but lacks direct sales or closing experience, which is a core requirement for the Inbound Sales Consultant role. While familiar with call documentation and issue resolution, there is no evidence of meeting sales KPIs, handling high-end clients, or making travel recommendations. Overall, alignment with the JD is low due to the absence of sales background.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Elena R. Castillo.pdf (Candidate 8/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Pharmaceutical Sales Rep\",\n",
      "      \"company\": \"SunHealth Pharma\",\n",
      "      \"start_date\": \"2019-05\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"May 2019 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Medical Sales Associate\",\n",
      "      \"company\": \"CuraMed Devices\",\n",
      "      \"start_date\": \"2017-06\",\n",
      "      \"end_date\": \"2019-04\",\n",
      "      \"raw_tenure_text\": \"Jun 2017 – Apr 2019\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Phoenix\",\n",
      "    \"state\": \"AZ\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Phoenix, AZ\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has over 5 years of remote and phone-based sales experience, consistently exceeding sales targets and demonstrating strong relationship-building and objection-handling skills. While her background is in pharmaceutical and medical sales rather than travel, her proven success in remote sales roles and KPI attainment suggests a strong foundational fit for the Inbound Sales Consultant position. No direct travel industry experience is evident, but her transferable sales skills and remote work discipline align well with the JD requirements.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Jason T. Kim.pdf (Candidate 9/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Inside Sales Assistant\",\n",
      "      \"company\": \"Metro Logistics Solutions\",\n",
      "      \"start_date\": \"2022-09\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Sep 2022 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Sales Intern\",\n",
      "      \"company\": \"Northwest Supply Co.\",\n",
      "      \"start_date\": \"2021-06\",\n",
      "      \"end_date\": \"2022-08\",\n",
      "      \"raw_tenure_text\": \"Jun 2021 – Aug 2022\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Portland\",\n",
      "    \"state\": \"OR\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Portland, OR\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has 2 years of inside sales support experience, primarily in B2B environments, with exposure to outbound calling and CRM management. However, they lack the required 5+ years of sales experience, proven phone-based sales closing, and direct B2C or travel industry background. Overall, the candidate appears to be entry-level and does not meet the seniority or specific experience requirements of the JD.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Jessica L. Morgan.pdf (Candidate 10/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Senior Travel Sales Consultant\",\n",
      "      \"company\": \"Voyage Elite Group\",\n",
      "      \"start_date\": \"2019-03\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Mar 2019 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Travel Coordinator\",\n",
      "      \"company\": \"JetWorld Travel\",\n",
      "      \"start_date\": \"2015-07\",\n",
      "      \"end_date\": \"2019-02\",\n",
      "      \"raw_tenure_text\": \"Jul 2015 – Feb 2019\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Houston\",\n",
      "    \"state\": \"TX\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Houston, TX\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"Jessica has over 7 years of remote, high-value travel sales experience, including extensive phone-based sales, relationship-building with VIP clients, and a strong record of exceeding sales quotas. Her background in luxury travel and pipeline management aligns closely with the requirements for the Inbound Sales Consultant role at ABC Cruises. She appears highly suitable for the position based on her relevant skills and industry experience.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Kevin J. Stone.pdf (Candidate 11/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Shift Leader / Barista\",\n",
      "      \"company\": \"Seaside Coffee Co.\",\n",
      "      \"start_date\": \"2021-02\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Feb 2021 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Barista\",\n",
      "      \"company\": \"Bean Street Café\",\n",
      "      \"start_date\": \"2020-07\",\n",
      "      \"end_date\": \"2021-01\",\n",
      "      \"raw_tenure_text\": \"Jul 2020 – Jan 2021\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Portland\",\n",
      "    \"state\": \"ME\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Portland, ME\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has strong customer service experience and some leadership skills from the food service industry but lacks any direct sales, telephone sales, or travel industry experience required by the job description. There is no evidence of meeting sales KPIs, handling high-end clients, or working in a remote/virtual environment. Overall, the resume does not align well with the requirements for the Inbound Sales Consultant role at ABC Cruises.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Lauren K. Smith.pdf (Candidate 12/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Indianapolis\",\n",
      "    \"state\": \"IN\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Indianapolis, IN\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate is a recent college graduate with no professional experience and no sales background. While they demonstrate strong communication and organizational skills, they lack the required sales experience, phone sales expertise, and industry knowledge specified in the job description. Overall, there is minimal alignment with the requirements for the Inbound Sales Consultant role.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Mark L. Thompson.pdf (Candidate 13/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Sales Consultant\",\n",
      "      \"company\": \"NextGen Solutions\",\n",
      "      \"start_date\": \"2019-01\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Jan 2019 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Account Executive\",\n",
      "      \"company\": \"CloudPrime\",\n",
      "      \"start_date\": \"2017-06\",\n",
      "      \"end_date\": \"2018-12\",\n",
      "      \"raw_tenure_text\": \"Jun 2017 – Dec 2018\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Boston\",\n",
      "    \"state\": \"MA\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Boston, MA\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has over 6 years of experience in remote B2B/B2C sales, including extensive phone-based selling and full-cycle account management, which aligns well with the inbound sales and relationship-building aspects of the JD. However, there is no direct experience in the travel or cruise industry, nor explicit mention of working with high-net-worth clients or handling inbound sales calls. Overall, the candidate demonstrates strong sales skills and remote work capability, but lacks specific travel industry background.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Morgan L. Wright.pdf (Candidate 14/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Sales Associate\",\n",
      "      \"company\": \"UrbanStyle Fashions\",\n",
      "      \"start_date\": \"2019-05\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"May 2019 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Cashier & Stock Assistant\",\n",
      "      \"company\": \"TrendMart\",\n",
      "      \"start_date\": \"2017-09\",\n",
      "      \"end_date\": \"2019-04\",\n",
      "      \"raw_tenure_text\": \"Sep 2017 – Apr 2019\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Columbus\",\n",
      "    \"state\": \"OH\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Columbus, OH\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has 5 years of in-person retail sales experience, demonstrating skills in upselling, customer service, and meeting sales goals. However, there is no evidence of telephone or remote sales experience, nor experience with high-end travel or cruise sales. While motivated and seeking a remote sales role, the alignment with the JD is limited due to lack of relevant industry and phone-based sales background.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Omar S. Farouk.pdf (Candidate 15/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Account Manager\",\n",
      "      \"company\": \"Midwest Supply Group\",\n",
      "      \"start_date\": \"2016-03\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Mar 2016 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Sales Coordinator\",\n",
      "      \"company\": \"ProTech Components\",\n",
      "      \"start_date\": \"2013-09\",\n",
      "      \"end_date\": \"2016-02\",\n",
      "      \"raw_tenure_text\": \"Sep 2013 – Feb 2016\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Detroit\",\n",
      "    \"state\": \"MI\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Detroit, MI\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has 7 years of B2B industrial sales experience, primarily in account management, contract negotiation, and client retention, but explicitly states no background in phone-based or B2C sales. While they demonstrate strong sales and relationship management skills, their lack of telephone and consumer-facing sales experience makes them a weak fit for the inbound sales consultant role focused on B2C travel sales.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Rebecca D. Miller.pdf (Candidate 16/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Kindergarten Teacher\",\n",
      "      \"company\": \"Lakeside Elementary\",\n",
      "      \"start_date\": \"2018-08\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Aug 2018 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Teacher’s Aide\",\n",
      "      \"company\": \"Happy Hearts Preschool\",\n",
      "      \"start_date\": \"2016-01\",\n",
      "      \"end_date\": \"2018-07\",\n",
      "      \"raw_tenure_text\": \"Jan 2016 – Jul 2018\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Minneapolis\",\n",
      "    \"state\": \"MN\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Minneapolis, MN\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has a strong background in early childhood education but lacks any direct sales, travel industry, or telephone-based sales experience as required by the job description. While communication and interpersonal skills are evident, there is no indication of experience with sales KPIs, closing sales, or working with high-end clients. Overall, the resume does not align with the core requirements of the Inbound Sales Consultant role at ABC Cruises.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Samantha Q. Evans.pdf (Candidate 17/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Graphic Designer\",\n",
      "      \"company\": \"BrightPixel Studio\",\n",
      "      \"start_date\": \"2022-09\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Sep 2022 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Design Intern\",\n",
      "      \"company\": \"AdFusion Marketing\",\n",
      "      \"start_date\": \"2022-01\",\n",
      "      \"end_date\": \"2022-08\",\n",
      "      \"raw_tenure_text\": \"Jan 2022 – Aug 2022\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Denver\",\n",
      "    \"state\": \"CO\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Denver, CO\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has a background in graphic design and marketing but lacks any direct sales, travel industry, or telephone-based experience as required by the job description. There is no evidence of sales KPIs, client relationship management, or relevant technical proficiencies for a remote inbound sales consultant role. Overall, the resume does not align with the core requirements of the position.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Samuel D. Reed.pdf (Candidate 18/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Remote Travel Sales Executive\",\n",
      "      \"company\": \"Luxury Horizons\",\n",
      "      \"start_date\": \"2018-06\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Jun 2018 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Sales Associate\",\n",
      "      \"company\": \"Vista Travel Network\",\n",
      "      \"start_date\": \"2014-08\",\n",
      "      \"end_date\": \"2018-05\",\n",
      "      \"raw_tenure_text\": \"Aug 2014 – May 2018\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"San Diego\",\n",
      "    \"state\": \"CA\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"San Diego, CA\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"Samuel D. Reed demonstrates strong alignment with the JD, offering over 9 years of sales experience in the high-end travel sector, including remote inbound sales, KPI overachievement, and consultative selling. His background in closing high-value bookings, upselling, and CRM proficiency matches the requirements for handling luxury cruise sales and building client relationships. The candidate appears highly suitable for the Inbound Sales Consultant role at ABC Cruises.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Sophia E. Lopez.pdf (Candidate 19/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Guest Service Supervisor\",\n",
      "      \"company\": \"La Belle Cuisine\",\n",
      "      \"start_date\": \"2020-11\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Nov 2020 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Hostess\",\n",
      "      \"company\": \"Fiesta Steakhouse\",\n",
      "      \"start_date\": \"2019-06\",\n",
      "      \"end_date\": \"2020-10\",\n",
      "      \"raw_tenure_text\": \"Jun 2019 – Oct 2020\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"San Antonio\",\n",
      "    \"state\": \"TX\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"San Antonio, TX\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has strong hospitality and guest service experience in upscale restaurant environments, with demonstrated skills in upselling, guest relations, and conflict resolution. However, there is no direct sales or telephone-based sales experience, nor evidence of meeting sales KPIs or working with high-end travel clients. While the customer service background is relevant, the candidate lacks the required sales tenure and specific travel industry experience outlined in the JD.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Tyler M. Harris.pdf (Candidate 20/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Data Analyst Intern\",\n",
      "      \"company\": \"Urban Insights\",\n",
      "      \"start_date\": \"2023-06\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Jun 2023 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Research Assistant\",\n",
      "      \"company\": \"University of Maryland\",\n",
      "      \"start_date\": \"2022-09\",\n",
      "      \"end_date\": \"2023-05\",\n",
      "      \"raw_tenure_text\": \"Sep 2022 – May 2023\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Baltimore\",\n",
      "    \"state\": \"MD\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Baltimore, MD\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate has no relevant sales or travel industry experience and lacks the required telephone sales background. Their experience is limited to data analysis and academic research, with no evidence of customer-facing or sales roles. Overall, there is minimal alignment with the job description for the Inbound Sales Consultant position.\"\n",
      "}\n",
      "----------------------------------------\n",
      "\n",
      "For Candidate File: Wei Lin.pdf (Candidate 21/21)\n",
      "Raw AI JSON String (or error message):\n",
      "{\n",
      "  \"job_history\": [\n",
      "    {\n",
      "      \"role\": \"Remote Travel Advisor\",\n",
      "      \"company\": \"Prestige Destinations\",\n",
      "      \"start_date\": \"2019-02\",\n",
      "      \"end_date\": \"2025-05-18\",\n",
      "      \"raw_tenure_text\": \"Feb 2019 – Present\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Account Coordinator\",\n",
      "      \"company\": \"Pacific Getaway Group\",\n",
      "      \"start_date\": \"2015-10\",\n",
      "      \"end_date\": \"2019-01\",\n",
      "      \"raw_tenure_text\": \"Oct 2015 – Jan 2019\"\n",
      "    }\n",
      "  ],\n",
      "  \"location_info\": {\n",
      "    \"city\": \"Boston\",\n",
      "    \"state\": \"MA\",\n",
      "    \"country\": \"USA\",\n",
      "    \"raw_location_text\": \"Boston, MA\"\n",
      "  },\n",
      "  \"jd_alignment_summary\": \"The candidate demonstrates strong alignment with the JD, offering 8 years of high-ticket phone sales experience in luxury travel, consistent KPI outperformance, and expertise in managing international, high-end clientele. Their background in remote sales, CRM pipeline management, and multilingual client service matches the requirements for inbound sales, relationship building, and closing sales over the phone. Overall, the candidate appears highly suitable for the Inbound Sales Consultant role at ABC Cruises.\"\n",
      "}\n",
      "----------------------------------------\n",
      "--- End of Raw AI JSON Output Inspection ---\n"
     ]
    }
   ],
   "source": [
    "# --- Optional: Verification of Raw AI JSON Outputs ---\n",
    "INSPECT_RAW_JSON_CANDIDATE_OUTPUTS = True # Set to True for debugging.\n",
    "\n",
    "if INSPECT_RAW_JSON_CANDIDATE_OUTPUTS and 'raw_ai_json_outputs_for_candidates' in locals() and raw_ai_json_outputs_for_candidates:\n",
    "    print(f\"\\n--- Raw AI JSON Outputs for Candidate Resumes ({len(raw_ai_json_outputs_for_candidates)} total) ---\")\n",
    "    for i, json_str_output in enumerate(raw_ai_json_outputs_for_candidates):\n",
    "        original_filename = os.path.basename(candidate_paths_for_processing[i]) if i < len(candidate_paths_for_processing) else \"Unknown Original\"\n",
    "        print(f\"\\nFor Candidate File: {original_filename} (Candidate {i+1}/{len(raw_ai_json_outputs_for_candidates)})\")\n",
    "        print(f\"Raw AI JSON String (or error message):\\n{json_str_output}\")\n",
    "        print(\"-\" * 40)\n",
    "    print(\"--- End of Raw AI JSON Output Inspection ---\")\n",
    "elif INSPECT_RAW_JSON_CANDIDATE_OUTPUTS:\n",
    "    print(\"\\nINFO: 'raw_ai_json_outputs_for_candidates' is empty or inspection is disabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Starting JSON parsing and rule-based filtering for 21 AI outputs...\n",
      "INFO: Filtering out 'Lauren K. Smith.pdf'. Reason: Average tenure of relevant roles 0.00 years (only roles >= 6 months counted) is less than required 1.0 year(s). (Average tenure of all roles: 0.00 years) (Relevant roles average: 0.00 years, All roles average: 0.00 years)\n",
      "\n",
      "INFO: JSON parsing and rule-based filtering completed.\n",
      "INFO: 20 candidate(s) passed all rules and have valid summaries prepared for embedding.\n",
      "INFO: 1 candidate(s) were filtered out due to rules or processing/data errors.\n",
      "\n",
      "--- Summaries Prepared for Embedding (20 total) ---\n",
      "\n",
      "For Embedding - File: Alexandra N. White.pdf (Item 1)\n",
      "Summary to be embedded (snippet):\n",
      "The candidate demonstrates over 6 years of remote travel sales experience, including direct sales, KPI achievement, and pipeline management in the travel industry. Their background in high-volume sale...\n",
      "------------------------------\n",
      "\n",
      "For Embedding - File: Amanda B. Chen.pdf (Item 2)\n",
      "Summary to be embedded (snippet):\n",
      "The candidate has over 8 years of high-end sales experience, primarily in luxury retail, with a strong track record in phone-based consultative selling, relationship management, and meeting sales targ...\n",
      "------------------------------\n",
      "\n",
      "For Embedding - File: Brian J. Walker.pdf (Item 3)\n",
      "Summary to be embedded (snippet):\n",
      "The candidate has over 6 years of inside sales experience, primarily in high-ticket real estate, with a strong track record in phone-based prospecting, objection handling, and exceeding sales targets....\n",
      "------------------------------\n",
      "  ... and 17 more summaries.\n",
      "\n",
      "--- Candidates Filtered Out (1 total) ---\n",
      "\n",
      "Filtered Out - File: Lauren K. Smith.pdf (Item 1)\n",
      "  Reason: Average tenure of relevant roles 0.00 years (only roles >= 6 months counted) is less than required 1.0 year(s). (Average tenure of all roles: 0.00 years)\n",
      "  Average tenure relevant roles: 0.00 years\n",
      "  Average tenure all roles: 0.00 years\n",
      "  Is USA based: Yes\n",
      "  Detected country: USA\n",
      "------------------------------\n",
      "--- End of Filtering Results Inspection ---\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Parse AI's JSON Output, Apply Python Rules, and Prepare Data for Embedding ---\n",
    "\n",
    "# This cell takes the raw JSON string outputs from the AI (for candidate resumes),\n",
    "# parses them, applies hard-coded rules (like tenure and location) using Python logic,\n",
    "# and then extracts the 'jd_alignment_summary' for those candidates who pass the rules.\n",
    "# These extracted summaries are then prepared for the subsequent embedding step.\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# Expected variables from the PREVIOUS cell:\n",
    "#   - 'raw_ai_json_outputs_for_candidates': A list of strings. Each string is expected to be\n",
    "#     a JSON object returned by the AI, or an error marker string if the API call failed.\n",
    "#   - 'candidate_paths_for_processing': A list of strings, holding the original file paths\n",
    "#     for the candidate resumes. This list MUST be synchronized with 'raw_ai_json_outputs_for_candidates'\n",
    "#     in terms of order and length.\n",
    "#\n",
    "# Required imported modules (ensure these are imported in one of the first cells of your notebook):\n",
    "#   - import json # For json.loads\n",
    "#   - import datetime # For datetime, date, timedelta - used in tenure calculation\n",
    "#   - import os # For os.path.basename - used in logging/error messages\n",
    "\n",
    "# --- Configuration for Rule-Based Filtering ---\n",
    "MINIMUM_AVERAGE_TENURE_YEARS = 1.0 # (e.g.) Minimum 1 year of average relevant work experience\n",
    "REQUIRED_COUNTRY = \"USA\" # Case-insensitive check will be applied\n",
    "MINIMUM_TENURE_PER_ROLE_MONTHS = 6 # (e.g.) A single role must last at least 6 months to be considered \"relevant\"\n",
    "\n",
    "# Helper function: Parses date strings from AI output (YYYY-MM, YYYY-MM-DD, YYYY) and handles \"Unknown\"\n",
    "def parse_date_from_ai(date_str):\n",
    "    \"\"\"\n",
    "    Parses a date string from AI output (expected \"YYYY-MM\", \"YYYY-MM-DD\", or \"YYYY\").\n",
    "    Returns a datetime.date object or None if parsing fails or input is \"Unknown\"/\"Not Specified\".\n",
    "    \"\"\"\n",
    "    if not date_str or date_str.lower() in [\"unknown\", \"not specified\"]:\n",
    "        return None\n",
    "    try:\n",
    "        if len(date_str) == 10 and date_str.count('-') == 2: # YYYY-MM-DD\n",
    "            return datetime.datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "        elif len(date_str) == 7 and date_str.count('-') == 1: # YYYY-MM\n",
    "            # Assume first day of the month for calculation if only YYYY-MM is given\n",
    "            return datetime.datetime.strptime(date_str + \"-01\", \"%Y-%m-%d\").date()\n",
    "        elif len(date_str) == 4 and date_str.isdigit(): # YYYY\n",
    "            # Assume Jan 1st of the year if only YYYY is given\n",
    "            return datetime.date(int(date_str), 1, 1)\n",
    "        else:\n",
    "            # print(f\"DEBUG: Unrecognized date format for parsing: '{date_str}'\") # Keep for debugging if needed\n",
    "            return None\n",
    "    except ValueError:\n",
    "        # print(f\"DEBUG: ValueError parsing date string: '{date_str}'\") # Keep for debugging if needed\n",
    "        return None\n",
    "\n",
    "# Helper function: Calculates tenure in years for a single role\n",
    "def calculate_single_role_tenure_years(start_date_obj, end_date_obj):\n",
    "    \"\"\"\n",
    "    Calculates tenure in years between two date objects.\n",
    "    Returns tenure in years (float) or 0.0 if dates are invalid or end_date < start_date.\n",
    "    \"\"\"\n",
    "    if not start_date_obj or not end_date_obj or end_date_obj < start_date_obj:\n",
    "        return 0.0\n",
    "    # Using dateutil.relativedelta for more precise year/month/day differences if available\n",
    "    # from dateutil.relativedelta import relativedelta\n",
    "    # delta = relativedelta(end_date_obj, start_date_obj)\n",
    "    # return delta.years + delta.months / 12 + delta.days / 365.25 # Approximation\n",
    "    delta = end_date_obj - start_date_obj\n",
    "    return delta.days / 365.25\n",
    "\n",
    "# Initialize output lists for THIS cell.\n",
    "# These will be used as inputs for the NEXT cell (Embedding Generation).\n",
    "final_resume_summaries_for_embedding = []\n",
    "final_resume_paths_for_embedding = []\n",
    "# Optional: For tracking which resumes were filtered out and why.\n",
    "filtered_out_candidates_info = []\n",
    "\n",
    "# --- Check if input lists are available and synchronized ---\n",
    "if not ('raw_ai_json_outputs_for_candidates' in locals() and \\\n",
    "        'candidate_paths_for_processing' in locals() and \\\n",
    "        isinstance(raw_ai_json_outputs_for_candidates, list) and \\\n",
    "        isinstance(candidate_paths_for_processing, list) and \\\n",
    "        len(raw_ai_json_outputs_for_candidates) == len(candidate_paths_for_processing)):\n",
    "    \n",
    "    print(\"CRITICAL ERROR: Input lists ('raw_ai_json_outputs_for_candidates' or 'candidate_paths_for_processing') \"\n",
    "          \"are missing, not lists, or their lengths do not match. Cannot proceed with filtering.\")\n",
    "    print(f\"  Length of 'raw_ai_json_outputs_for_candidates' (if exists): \"\n",
    "          f\"{len(raw_ai_json_outputs_for_candidates) if 'raw_ai_json_outputs_for_candidates' in locals() and isinstance(raw_ai_json_outputs_for_candidates, list) else 'Not a list or not defined'}\")\n",
    "    print(f\"  Length of 'candidate_paths_for_processing' (if exists): \"\n",
    "          f\"{len(candidate_paths_for_processing) if 'candidate_paths_for_processing' in locals() and isinstance(candidate_paths_for_processing, list) else 'Not a list or not defined'}\")\n",
    "else:\n",
    "    print(f\"INFO: Starting JSON parsing and rule-based filtering for {len(raw_ai_json_outputs_for_candidates)} AI outputs...\")\n",
    "    for i, raw_json_str in enumerate(raw_ai_json_outputs_for_candidates):\n",
    "        original_path = candidate_paths_for_processing[i]\n",
    "        original_filename = os.path.basename(original_path)\n",
    "        candidate_passed_rules = False \n",
    "        extracted_summary_for_embedding = \"\"\n",
    "        filter_reason = \"\"\n",
    "        \n",
    "        # Initialize tenure calculation variables\n",
    "        total_tenure_months_relevant_roles = 0.0\n",
    "        count_relevant_roles = 0\n",
    "        total_tenure_months_all_roles = 0.0\n",
    "        count_all_roles = 0\n",
    "        average_tenure_relevant_roles_years = 0.0\n",
    "        average_tenure_all_roles_years = 0.0\n",
    "        is_usa_based = False # Default to False\n",
    "\n",
    "        try:\n",
    "            # Check if raw_json_str is an error marker from the previous AI call\n",
    "            if isinstance(raw_json_str, str) and \"ERROR\" in raw_json_str.upper():\n",
    "                filter_reason = f\"AI processing error in the previous step: {raw_json_str}\" \n",
    "            # Check if it's a valid-looking JSON string\n",
    "            elif isinstance(raw_json_str, str) and raw_json_str.strip().startswith(\"{\") and raw_json_str.strip().endswith(\"}\"):\n",
    "                ai_data = json.loads(raw_json_str) # Attempt to parse\n",
    "\n",
    "                # --- Rule 1 & 2: Tenure Calculation (in Python) ---\n",
    "                job_history = ai_data.get(\"job_history\", [])\n",
    "                \n",
    "                if isinstance(job_history, list):\n",
    "                    for job in job_history:\n",
    "                        if isinstance(job, dict):\n",
    "                            start_date_str = job.get(\"start_date\")\n",
    "                            end_date_str = job.get(\"end_date\")\n",
    "                            \n",
    "                            start_date = parse_date_from_ai(start_date_str)\n",
    "                            end_date = parse_date_from_ai(end_date_str)\n",
    "\n",
    "                            if start_date and end_date and end_date >= start_date:\n",
    "                                tenure_years_this_role = calculate_single_role_tenure_years(start_date, end_date)\n",
    "                                tenure_months_this_role_float = tenure_years_this_role * 12.0\n",
    "                                \n",
    "                                # Accumulate all valid tenures\n",
    "                                if tenure_months_this_role_float > 0: # Count as long as it's a valid tenure\n",
    "                                    total_tenure_months_all_roles += tenure_months_this_role_float\n",
    "                                    count_all_roles += 1\n",
    "                                \n",
    "                                # Accumulate \"relevant\" tenures (meeting minimum single role duration)\n",
    "                                if tenure_months_this_role_float >= MINIMUM_TENURE_PER_ROLE_MONTHS:\n",
    "                                    total_tenure_months_relevant_roles += tenure_months_this_role_float\n",
    "                                    count_relevant_roles += 1\n",
    "                \n",
    "                if count_relevant_roles > 0:\n",
    "                    average_tenure_relevant_roles_years = (total_tenure_months_relevant_roles / count_relevant_roles) / 12.0\n",
    "                \n",
    "                if count_all_roles > 0:\n",
    "                    average_tenure_all_roles_years = (total_tenure_months_all_roles / count_all_roles) / 12.0\n",
    "                \n",
    "                # --- Rule 3: Location Check (in Python) ---\n",
    "                location_info = ai_data.get(\"location_info\", {})\n",
    "                country = \"Unknown\" # Default to Unknown\n",
    "                if isinstance(location_info, dict):\n",
    "                    country_from_ai = location_info.get(\"country\") \n",
    "                    if isinstance(country_from_ai, str) and country_from_ai.strip(): # Ensure country info is not empty\n",
    "                        country = country_from_ai\n",
    "                    elif country_from_ai is None:\n",
    "                         country = \"Unknown\" \n",
    "                \n",
    "                is_usa_based = (country.upper() == REQUIRED_COUNTRY.upper())\n",
    "\n",
    "                # --- Rule 4: Filtering Decision (based on Python calculations) ---\n",
    "                if not is_usa_based:\n",
    "                    filter_reason = f\"Candidate location not {REQUIRED_COUNTRY} (Detected country: {country}).\" \n",
    "                elif average_tenure_relevant_roles_years < MINIMUM_AVERAGE_TENURE_YEARS:\n",
    "                    filter_reason = (f\"Average tenure of relevant roles {average_tenure_relevant_roles_years:.2f} years (only roles >= {MINIMUM_TENURE_PER_ROLE_MONTHS} months counted) \" \n",
    "                                     f\"is less than required {MINIMUM_AVERAGE_TENURE_YEARS} year(s).\" \n",
    "                                     f\" (Average tenure of all roles: {average_tenure_all_roles_years:.2f} years)\") \n",
    "                else:\n",
    "                    candidate_passed_rules = True\n",
    "                    summary_from_ai = ai_data.get(\"jd_alignment_summary\", \"\").strip()\n",
    "                    if summary_from_ai:\n",
    "                        extracted_summary_for_embedding = summary_from_ai\n",
    "                    else:\n",
    "                        # Candidate passed rules, but AI didn't provide the summary in JSON.\n",
    "                        print(f\"WARNING: Candidate '{original_filename}' passed Python rules, but 'jd_alignment_summary' was missing or empty in AI's JSON output. Will be filtered out.\") \n",
    "                        # If summary is crucial for subsequent steps, treat as filtered out even if rules passed\n",
    "                        filter_reason = \"Passed rules but 'jd_alignment_summary' was missing or empty in AI's JSON output.\" \n",
    "                        candidate_passed_rules = False \n",
    "            else: # raw_json_str is not a string or does not look like JSON\n",
    "                filter_reason = f\"Invalid AI output format (not a valid JSON string). Snippet: {str(raw_json_str)[:100]}\" \n",
    "\n",
    "        except json.JSONDecodeError as je:\n",
    "            filter_reason = f\"JSON Decode Error: {je}. Raw AI output snippet: {raw_json_str[:200]}...\" \n",
    "        except Exception as e:\n",
    "            filter_reason = f\"Unexpected error processing JSON/rules for '{original_filename}'. Error: {type(e).__name__} - {e}\" \n",
    "\n",
    "        # --- Populate output lists ---\n",
    "        if candidate_passed_rules and extracted_summary_for_embedding:\n",
    "            final_resume_summaries_for_embedding.append(extracted_summary_for_embedding)\n",
    "            final_resume_paths_for_embedding.append(original_path)\n",
    "        else:\n",
    "            if not filter_reason: # If no specific reason was set before\n",
    "                filter_reason = \"Did not pass rule-based filtering or critical summary was missing.\" \n",
    "            \n",
    "            # Add more detailed tenure and location info when printing filter message\n",
    "            log_message = f\"INFO: Filtering out '{original_filename}'. Reason: {filter_reason}\" \n",
    "            if \"tenure\" in filter_reason.lower(): # If reason is tenure-related (check in lowercase for robustness)\n",
    "                 log_message += (f\" (Relevant roles average: {average_tenure_relevant_roles_years:.2f} years, \" \n",
    "                                 f\"All roles average: {average_tenure_all_roles_years:.2f} years)\") \n",
    "            if \"location\" in filter_reason.lower() and not is_usa_based: # If reason is location-related and not USA based\n",
    "                 log_message += f\" (Determined location: {country})\" \n",
    "\n",
    "            print(log_message)\n",
    "            filtered_out_candidates_info.append({\n",
    "                \"path\": original_path,\n",
    "                \"filename\": original_filename,\n",
    "                \"reason\": filter_reason,\n",
    "                \"avg_tenure_relevant_roles\": average_tenure_relevant_roles_years,\n",
    "                \"avg_tenure_all_roles\": average_tenure_all_roles_years,\n",
    "                \"is_usa_based\": is_usa_based,\n",
    "                \"country_detected\": country if 'country' in locals() else \"Not detected\" \n",
    "            })\n",
    "\n",
    "    print(f\"\\nINFO: JSON parsing and rule-based filtering completed.\") \n",
    "    print(f\"INFO: {len(final_resume_summaries_for_embedding)} candidate(s) passed all rules and have valid summaries prepared for embedding.\") \n",
    "    print(f\"INFO: {len(filtered_out_candidates_info)} candidate(s) were filtered out due to rules or processing/data errors.\") \n",
    "\n",
    "# --- Optional: Verification of outputs of this cell ---\n",
    "INSPECT_FILTERING_RESULTS = True # Set to True to see the outputs of this cell\n",
    "\n",
    "if INSPECT_FILTERING_RESULTS:\n",
    "    if final_resume_summaries_for_embedding:\n",
    "        print(f\"\\n--- Summaries Prepared for Embedding ({len(final_resume_summaries_for_embedding)} total) ---\") \n",
    "        # Show only the first few as examples to avoid excessive output\n",
    "        for i in range(min(3, len(final_resume_summaries_for_embedding))): \n",
    "            original_filename = os.path.basename(final_resume_paths_for_embedding[i])\n",
    "            print(f\"\\nFor Embedding - File: {original_filename} (Item {i+1})\") \n",
    "            print(f\"Summary to be embedded (snippet):\\n{final_resume_summaries_for_embedding[i][:200]}...\") \n",
    "            print(\"-\" * 30)\n",
    "        if len(final_resume_summaries_for_embedding) > 3:\n",
    "            print(f\"  ... and {len(final_resume_summaries_for_embedding) - 3} more summaries.\") \n",
    "    else:\n",
    "        print(\"\\nINFO: No summaries prepared for embedding (list is empty).\") \n",
    "\n",
    "    if filtered_out_candidates_info:\n",
    "        print(f\"\\n--- Candidates Filtered Out ({len(filtered_out_candidates_info)} total) ---\") \n",
    "        # Show only the first few as examples\n",
    "        for i, filtered_info in enumerate(filtered_out_candidates_info[:3]): \n",
    "            print(f\"\\nFiltered Out - File: {filtered_info.get('filename', 'N/A')} (Item {i+1})\") \n",
    "            print(f\"  Reason: {filtered_info.get('reason', 'N/A')}\") \n",
    "            print(f\"  Average tenure relevant roles: {filtered_info.get('avg_tenure_relevant_roles', 0.0):.2f} years\") \n",
    "            print(f\"  Average tenure all roles: {filtered_info.get('avg_tenure_all_roles', 0.0):.2f} years\") \n",
    "            print(f\"  Is USA based: {'Yes' if filtered_info.get('is_usa_based') else 'No'}\") \n",
    "            print(f\"  Detected country: {filtered_info.get('country_detected', 'Not detected')}\") \n",
    "            print(\"-\" * 30)\n",
    "        if len(filtered_out_candidates_info) > 3:\n",
    "            print(f\"  ... and {len(filtered_out_candidates_info) - 3} more filtered out candidates.\") \n",
    "    else:\n",
    "        print(\"\\nINFO: No candidates were filtered out by rules in this run (or list is empty).\") \n",
    "        \n",
    "    print(\"--- End of Filtering Results Inspection ---\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Loading Sentence Transformer model: 'all-mpnet-base-v2'...\n",
      "INFO: Sentence Transformer model 'all-mpnet-base-v2' loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize the Sentence Transformer Model ---\n",
    "\n",
    "# This cell loads a Sentence Transformer model to convert text into semantic vector embeddings.\n",
    "# These embeddings are then used for calculating similarity between resume summaries and sample summaries.\n",
    "\n",
    "# Current choice: 'all-mpnet-base-v2' - a strong general-purpose model from the sentence-transformers library.\n",
    "# It balances performance (embedding quality) with local inference speed and model size.\n",
    "SENTENCE_TRANSFORMER_MODEL_NAME = 'all-mpnet-base-v2'\n",
    "# Previous model tried: 'paraphrase-MiniLM-L6-v2' # This was the model used before switching to all-mpnet-base-v2\n",
    "\n",
    "# Alternative approach for generating embeddings:\n",
    "# OpenAI's Embedding API (e.g., \"text-embedding-3-small\" or \"text-embedding-3-large\")\n",
    "# could also be used here. This would involve:\n",
    "#   1. Making API calls to OpenAI for each text to be embedded.\n",
    "#   2. Handling potential API costs and rate limits.\n",
    "#   3. Benefits might include potentially higher quality embeddings from larger, regularly updated models,\n",
    "#      and no need to download/manage local model files.\n",
    "#   This project currently uses a local SentenceTransformer model for ease of setup and cost control.\n",
    "\n",
    "try:\n",
    "    print(f\"INFO: Loading Sentence Transformer model: '{SENTENCE_TRANSFORMER_MODEL_NAME}'...\")\n",
    "    # Ensure 'SentenceTransformer' class is imported from sentence_transformers library\n",
    "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL_NAME)\n",
    "    print(f\"INFO: Sentence Transformer model '{SENTENCE_TRANSFORMER_MODEL_NAME}' loaded successfully.\")\n",
    "    \n",
    "    # Optional: Specify device for the model (e.g., 'cuda' for GPU, 'cpu' for CPU)\n",
    "    # model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL_NAME, device='cuda')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: Failed to load the Sentence Transformer model '{SENTENCE_TRANSFORMER_MODEL_NAME}'.\")\n",
    "    print(f\"Error details: {e}\")\n",
    "    print(\"Please ensure the 'sentence-transformers' library and its dependencies (like PyTorch/TensorFlow) are installed correctly.\")\n",
    "    print(\"An internet connection might be required for the first-time model download.\")\n",
    "    model = None # Indicate model loading failure\n",
    "    # Consider raising the exception or exiting if the model is essential for subsequent steps:\n",
    "    # raise RuntimeError(f\"Could not load Sentence Transformer model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Initialize OpenAI Client (if not already done) ---\n",
    "# # Make sure your API key is set, e.g., via environment variable\n",
    "# # client = openai.OpenAI() # client.api_key will be read from OPENAI_API_KEY env var by default\n",
    "# # Or if you had openai.api_key = \"...\" from old SDK style, you might need to adapt.\n",
    "# # For this example, let's assume 'openai' module is configured with the key.\n",
    "\n",
    "# # --- Configuration for OpenAI Embedding ---\n",
    "# OPENAI_EMBEDDING_MODEL = \"text-embedding-3-small\" # Or \"text-embedding-3-large\", \"text-embedding-ada-002\"\n",
    "\n",
    "# def get_openai_embeddings_batch(texts: list[str], model_name: str = OPENAI_EMBEDDING_MODEL) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Gets embeddings for a batch of texts using OpenAI's API.\n",
    "#     Handles potential errors and returns a NumPy array of embeddings.\n",
    "#     \"\"\"\n",
    "#     if not texts:\n",
    "#         return np.array([])\n",
    "    \n",
    "#     # OpenAI recommends replacing newlines with spaces for their embedding models\n",
    "#     # and notes that models might perform worse on inputs with many newlines.\n",
    "#     processed_texts = [text.replace(\"\\n\", \" \") for text in texts]\n",
    "    \n",
    "#     try:\n",
    "#         # Note: The exact way to call might depend on your openai library version.\n",
    "#         # This example assumes a newer openai SDK (v1.x.x style might be client.embeddings.create)\n",
    "#         # If using an older SDK, it might be openai.Embedding.create(...)\n",
    "#         # Let's use a more generic try for older versions for now.\n",
    "#         response = openai.Embedding.create(input=processed_texts, model=model_name) # Older SDK style\n",
    "#         # For newer SDK (v1.0+):\n",
    "#         # from openai import OpenAI\n",
    "#         # client = OpenAI()\n",
    "#         # response = client.embeddings.create(input=processed_texts, model=model_name)\n",
    "        \n",
    "#         # Extract embeddings from the response\n",
    "#         # The structure of 'response' depends on the SDK version.\n",
    "#         # For older versions (like 0.28.0), it's often like this:\n",
    "#         embeddings = [item['embedding'] for item in response['data']]\n",
    "#         return np.array(embeddings)\n",
    "#     except openai.error.OpenAIError as e: # Catch specific OpenAI errors\n",
    "#         print(f\"ERROR: OpenAI API error while getting embeddings: {e}\")\n",
    "#         # Return an empty array or an array of zeros/NaNs matching expected shape if possible\n",
    "#         return np.array([]) \n",
    "#     except Exception as e:\n",
    "#         print(f\"ERROR: An unexpected error occurred while getting OpenAI embeddings: {e}\")\n",
    "#         return np.array([])\n",
    "\n",
    "# # --- Replace previous model.encode() calls ---\n",
    "\n",
    "# # It's assumed that 'sample_outputs' and 'resume_outputs' (lists of strings)\n",
    "# # have been generated by the OpenAI ChatCompletion API in previous cells.\n",
    "\n",
    "# if sample_outputs:\n",
    "#     print(f\"INFO: Generating OpenAI embeddings for {len(sample_outputs)} sample outputs using model '{OPENAI_EMBEDDING_MODEL}'...\")\n",
    "#     sample_embeddings = get_openai_embeddings_batch(sample_outputs)\n",
    "#     if sample_embeddings.size > 0:\n",
    "#         print(f\"INFO: Generated {sample_embeddings.shape[0]} OpenAI embeddings for sample outputs, each with dimension {sample_embeddings.shape[1]}.\")\n",
    "#     else:\n",
    "#         print(\"WARNING: Failed to generate OpenAI embeddings for sample outputs or list was empty.\")\n",
    "# else:\n",
    "#     print(\"WARNING: 'sample_outputs' list is empty. No sample embeddings will be generated.\")\n",
    "#     sample_embeddings = np.array([])\n",
    "\n",
    "# if resume_outputs:\n",
    "#     print(f\"INFO: Generating OpenAI embeddings for {len(resume_outputs)} resume outputs using model '{OPENAI_EMBEDDING_MODEL}'...\")\n",
    "#     # Before sending resume_outputs to embedding, you might need to filter out\n",
    "#     # those that are just \"tenure too short\" or \"not from USA\" messages,\n",
    "#     # as embedding these messages might not be meaningful for similarity comparison.\n",
    "#     # Example of filtering (you'll need to define what constitutes a \"valid\" summary):\n",
    "#     # valid_resume_outputs_for_embedding = [\n",
    "#     #     out for out in resume_outputs \n",
    "#     #     if not out.startswith(\"Candidate not based in USA\") and \\\n",
    "#     #        not out.startswith(\"Average tenure less than 1 year\") and \\\n",
    "#     #        not out.startswith(\"AI_PROCESSING_ERROR\") # and other error markers\n",
    "#     # ]\n",
    "#     # print(f\"INFO: Found {len(valid_resume_outputs_for_embedding)} valid resume outputs to embed out of {len(resume_outputs)} total.\")\n",
    "#     # if valid_resume_outputs_for_embedding:\n",
    "#     #    resume_embeddings = get_openai_embeddings_batch(valid_resume_outputs_for_embedding)\n",
    "#     #    # ... (rest of the logic, be mindful that resume_embeddings might now be shorter than resume_outputs/resume_paths)\n",
    "#     # else:\n",
    "#     #    resume_embeddings = np.array([])\n",
    "#     # For simplicity in this direct replacement example, we'll encode all:\n",
    "#     resume_embeddings = get_openai_embeddings_batch(resume_outputs)\n",
    "#     if resume_embeddings.size > 0:\n",
    "#         print(f\"INFO: Generated {resume_embeddings.shape[0]} OpenAI embeddings for resume outputs, each with dimension {resume_embeddings.shape[1]}.\")\n",
    "#     else:\n",
    "#         print(\"WARNING: Failed to generate OpenAI embeddings for resume outputs or list was empty.\")\n",
    "# else:\n",
    "#     print(\"WARNING: 'resume_outputs' list is empty. No resume embeddings will be generated.\")\n",
    "#     resume_embeddings = np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Preparing to generate embeddings using model 'all-mpnet-base-v2'.\n",
      "INFO: Encoding 5 AI-generated summaries for sample resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Generated 5 embeddings for sample outputs, each with dimension 768.\n",
      "INFO: Encoding 20 AI-generated summaries for filtered candidate resumes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Generated 20 embeddings for filtered candidate resume summaries, each with dimension 768.\n",
      "DEBUG: Shape of sample_embeddings: (5, 768)\n",
      "DEBUG: Shape of resume_embeddings: (20, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Generate Embeddings for Processed Summaries ---\n",
    "\n",
    "# This cell takes the AI-generated textual summaries for \"good\" sample resumes ('sample_outputs')\n",
    "# AND the filtered, AI-generated textual summaries for candidate resumes that passed\n",
    "# hard-coded rules ('final_resume_summaries_for_embedding'), and converts them into\n",
    "# dense vector embeddings using the loaded Sentence Transformer model.\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# Expected variables from previous cells:\n",
    "#   - 'model': A loaded SentenceTransformer model object (from SentenceTransformer(SENTENCE_TRANSFORMER_MODEL_NAME)).\n",
    "#     This should have been successfully initialized.\n",
    "#   - 'sample_outputs': A list of strings. Each string is the AI-generated \"ideal_match_summary\"\n",
    "#     (or direct summary) for a \"good\" sample resume. This list should only contain summaries\n",
    "#     ready for embedding.\n",
    "#   - 'final_resume_summaries_for_embedding': A list of strings. Each string is the\n",
    "#     AI-generated \"jd_alignment_summary\" (extracted from JSON) for a candidate resume\n",
    "#     that has PASSED the Python-based rule filtering (e.g., tenure, location).\n",
    "#     This list should only contain summaries of qualified candidates ready for embedding.\n",
    "#\n",
    "# Required imported modules:\n",
    "#   - 'numpy' (as np)\n",
    "#   - 'SENTENCE_TRANSFORMER_MODEL_NAME' (string, for logging purposes, defined when model was loaded)\n",
    "\n",
    "# Initialize embedding variables to ensure they exist, even if an input list is empty or model loading failed.\n",
    "sample_embeddings = np.array([]) # Using an empty NumPy array as a default.\n",
    "resume_embeddings = np.array([]) # Using an empty NumPy array as a default.\n",
    "\n",
    "print(f\"INFO: Preparing to generate embeddings using model '{SENTENCE_TRANSFORMER_MODEL_NAME}'.\")\n",
    "\n",
    "# Ensure the Sentence Transformer model was loaded successfully before attempting to use it.\n",
    "if 'model' in locals() and model is not None:\n",
    "    \n",
    "    # --- Encode Sample Output Summaries ---\n",
    "    # Check if 'sample_outputs' exists, is a list, and is not empty.\n",
    "    if 'sample_outputs' in locals() and isinstance(sample_outputs, list) and len(sample_outputs) > 0:\n",
    "        # Defensive check: ensure all elements are strings.\n",
    "        if all(isinstance(s, str) for s in sample_outputs):\n",
    "            print(f\"INFO: Encoding {len(sample_outputs)} AI-generated summaries for sample resumes...\")\n",
    "            try:\n",
    "                sample_embeddings = model.encode(sample_outputs, show_progress_bar=True)\n",
    "                print(f\"INFO: Generated {sample_embeddings.shape[0]} embeddings for sample outputs, \"\n",
    "                      f\"each with dimension {sample_embeddings.shape[1]}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: Failed to encode 'sample_outputs'. Error: {e}\")\n",
    "                # sample_embeddings remains an empty np.array\n",
    "        else:\n",
    "            print(\"ERROR: 'sample_outputs' contains non-string elements. Encoding aborted for samples.\")\n",
    "    else:\n",
    "        print(\"WARNING: 'sample_outputs' list is empty or not valid. No sample embeddings will be generated. \"\n",
    "              \"This will critically affect scoring.\")\n",
    "\n",
    "    # --- Encode Filtered Candidate Resume Summaries ---\n",
    "    # Check if 'final_resume_summaries_for_embedding' exists, is a list, and is not empty.\n",
    "    # This list is the output from the \"Cell: Parse AI's JSON Output, Apply Python Rules...\"\n",
    "    if 'final_resume_summaries_for_embedding' in locals() and \\\n",
    "       isinstance(final_resume_summaries_for_embedding, list) and \\\n",
    "       len(final_resume_summaries_for_embedding) > 0:\n",
    "        \n",
    "        # Defensive check: ensure all elements are strings.\n",
    "        if all(isinstance(s, str) for s in final_resume_summaries_for_embedding):\n",
    "            print(f\"INFO: Encoding {len(final_resume_summaries_for_embedding)} AI-generated summaries for \"\n",
    "                  \"filtered candidate resumes...\")\n",
    "            try:\n",
    "                resume_embeddings = model.encode(final_resume_summaries_for_embedding, show_progress_bar=True)\n",
    "                print(f\"INFO: Generated {resume_embeddings.shape[0]} embeddings for filtered candidate resume summaries, \"\n",
    "                      f\"each with dimension {resume_embeddings.shape[1]}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: Failed to encode 'final_resume_summaries_for_embedding'. Error: {e}\")\n",
    "                # resume_embeddings remains an empty np.array\n",
    "        else:\n",
    "            print(\"ERROR: 'final_resume_summaries_for_embedding' contains non-string elements. \"\n",
    "                  \"Encoding aborted for candidate resumes.\")\n",
    "    else:\n",
    "        print(\"WARNING: 'final_resume_summaries_for_embedding' list is empty or not valid. \"\n",
    "              \"No candidate resume embeddings will be generated. This means no candidates passed prior filtering \"\n",
    "              \"or there were issues generating their summaries.\")\n",
    "\n",
    "else:\n",
    "    # This block executes if the 'model' from the previous cell was not loaded successfully.\n",
    "    print(\"CRITICAL ERROR: Sentence Transformer model ('model') is None. Cannot generate embeddings.\")\n",
    "    print(\"              Please ensure the model was loaded correctly in the preceding cell.\")\n",
    "\n",
    "# --- Optional: Verification of Embedding Shapes ---\n",
    "# Useful during development to confirm embeddings were generated and have the expected dimensions.\n",
    "INSPECT_EMBEDDING_SHAPES = True # Set to True to print shapes.\n",
    "\n",
    "if INSPECT_EMBEDDING_SHAPES:\n",
    "    if 'sample_embeddings' in locals() and isinstance(sample_embeddings, np.ndarray) and sample_embeddings.size > 0:\n",
    "        print(f\"DEBUG: Shape of sample_embeddings: {sample_embeddings.shape}\")\n",
    "    else:\n",
    "        print(\"DEBUG: 'sample_embeddings' is empty or was not generated.\")\n",
    "\n",
    "    if 'resume_embeddings' in locals() and isinstance(resume_embeddings, np.ndarray) and resume_embeddings.size > 0:\n",
    "        print(f\"DEBUG: Shape of resume_embeddings: {resume_embeddings.shape}\")\n",
    "    else:\n",
    "        print(\"DEBUG: 'resume_embeddings' is empty or was not generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Starting similarity score calculation for 20 candidate resume(s) against 5 sample resume profile(s)...\n",
      "INFO: Finished calculating similarity scores. Generated detailed scoring data for 20 candidate resume(s).\n",
      "\n",
      "--- Detailed Scores for All Processed Candidates (20 Total) ---\n",
      "\n",
      "Candidate File: Alexandra N. White.pdf (Item 1)\n",
      "  Best Score: 0.9225\n",
      "  Best Matching Sample: Michael D. Lee.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Amanda B. Chen.pdf (Item 2)\n",
      "  Best Score: 0.8806\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Brian J. Walker.pdf (Item 3)\n",
      "  Best Score: 0.8776\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Chloe R. Johnson.pdf (Item 4)\n",
      "  Best Score: 0.7327\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Christopher N. Patel.pdf (Item 5)\n",
      "  Best Score: 0.8687\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: David S. King.pdf (Item 6)\n",
      "  Best Score: 0.8848\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Derek J. Nelson.pdf (Item 7)\n",
      "  Best Score: 0.6592\n",
      "  Best Matching Sample: John R. Williams.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Elena R. Castillo.pdf (Item 8)\n",
      "  Best Score: 0.7999\n",
      "  Best Matching Sample: John R. Williams.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Jason T. Kim.pdf (Item 9)\n",
      "  Best Score: 0.4899\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Jessica L. Morgan.pdf (Item 10)\n",
      "  Best Score: 0.9075\n",
      "  Best Matching Sample: Linda J. Park.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Kevin J. Stone.pdf (Item 11)\n",
      "  Best Score: 0.7374\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Mark L. Thompson.pdf (Item 12)\n",
      "  Best Score: 0.7618\n",
      "  Best Matching Sample: Michael D. Lee.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Morgan L. Wright.pdf (Item 13)\n",
      "  Best Score: 0.7533\n",
      "  Best Matching Sample: John R. Williams.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Omar S. Farouk.pdf (Item 14)\n",
      "  Best Score: 0.7837\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Rebecca D. Miller.pdf (Item 15)\n",
      "  Best Score: 0.7668\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Samantha Q. Evans.pdf (Item 16)\n",
      "  Best Score: 0.6135\n",
      "  Best Matching Sample: John R. Williams.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Samuel D. Reed.pdf (Item 17)\n",
      "  Best Score: 0.8694\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Sophia E. Lopez.pdf (Item 18)\n",
      "  Best Score: 0.6323\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Tyler M. Harris.pdf (Item 19)\n",
      "  Best Score: 0.6868\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "\n",
      "Candidate File: Wei Lin.pdf (Item 20)\n",
      "  Best Score: 0.9143\n",
      "  Best Matching Sample: Emily S. Turner.pdf\n",
      "----------------------------------------\n",
      "--- End of Detailed Scores for All Processed Candidates ---\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Calculate Comprehensive Similarity Scores for Candidate Resumes ---\n",
    "\n",
    "# This cell calculates a \"best match\" similarity score for each candidate resume\n",
    "# against all available sample resume profiles. It populates a list called\n",
    "# 'processed_candidate_data' with detailed scoring information for each candidate.\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# Expected variables from previous cells:\n",
    "#   - 'model': The loaded SentenceTransformer model object (checked for existence).\n",
    "#   - 'sample_embeddings': NumPy array of embeddings for 'sample_outputs'.\n",
    "#     Its length and order MUST strictly correspond to 'sample_paths_processed'.\n",
    "#   - 'sample_paths_processed': List of file paths for original sample resumes,\n",
    "#     synchronized with 'sample_outputs' from which 'sample_embeddings' were generated.\n",
    "#   - 'resume_embeddings': NumPy array of embeddings for 'final_resume_summaries_for_embedding'.\n",
    "#     Its length and order MUST strictly correspond to 'final_resume_paths_for_embedding'.\n",
    "#   - 'final_resume_paths_for_embedding': List of file paths for candidate resumes that passed\n",
    "#     filtering, synchronized with 'final_resume_summaries_for_embedding'.\n",
    "#\n",
    "# Required imported modules/functions:\n",
    "#   - 'cosine_similarity' from 'sklearn.metrics.pairwise'\n",
    "#   - 'os' (for os.path.basename)\n",
    "#   - 'np' (NumPy) module.\n",
    "\n",
    "# Initialize the list to store processed candidate data\n",
    "processed_candidate_data = [] \n",
    "\n",
    "# Default score information for a candidate if scoring cannot be performed properly\n",
    "DEFAULT_SCORE_INFO_FOR_CANDIDATE = {\n",
    "    \"best_score\": 0.0,\n",
    "    \"best_matching_sample_path\": \"N/A\",\n",
    "    \"best_matching_sample_filename\": \"N/A\"\n",
    "}\n",
    "\n",
    "# --- Sanity Checks for Inputs ---\n",
    "model_loaded_successfully = ('model' in locals() and model is not None)\n",
    "\n",
    "# Check sample embeddings and their corresponding paths\n",
    "sample_data_valid = (\n",
    "    'sample_embeddings' in locals() and isinstance(sample_embeddings, np.ndarray) and sample_embeddings.size > 0 and\n",
    "    'sample_paths_processed' in locals() and isinstance(sample_paths_processed, list) and\n",
    "    len(sample_embeddings) == len(sample_paths_processed)\n",
    ")\n",
    "\n",
    "# Check candidate embeddings and their corresponding paths\n",
    "candidate_data_valid = (\n",
    "    'resume_embeddings' in locals() and isinstance(resume_embeddings, np.ndarray) and resume_embeddings.size > 0 and\n",
    "    'final_resume_paths_for_embedding' in locals() and isinstance(final_resume_paths_for_embedding, list) and\n",
    "    len(resume_embeddings) == len(final_resume_paths_for_embedding)\n",
    ")\n",
    "\n",
    "if not model_loaded_successfully:\n",
    "    print(\"CRITICAL ERROR: Sentence Transformer model ('model') is not loaded. Scoring aborted.\")\n",
    "elif not sample_data_valid:\n",
    "    print(\"CRITICAL ERROR: 'sample_embeddings' is invalid, empty, or not synchronized with 'sample_paths_processed'. \"\n",
    "          \"Cannot perform meaningful scoring. All candidates will receive default scores if candidate data is present.\")\n",
    "    # If sample data is invalid, but we have candidate paths, populate with default scores\n",
    "    if 'final_resume_paths_for_embedding' in locals() and isinstance(final_resume_paths_for_embedding, list):\n",
    "        for candidate_path in final_resume_paths_for_embedding:\n",
    "            processed_candidate_data.append({\n",
    "                \"candidate_path\": candidate_path,\n",
    "                \"candidate_filename\": os.path.basename(candidate_path),\n",
    "                **DEFAULT_SCORE_INFO_FOR_CANDIDATE\n",
    "            })\n",
    "elif not candidate_data_valid:\n",
    "    print(\"WARNING: 'resume_embeddings' is invalid, empty, or not synchronized with 'final_resume_paths_for_embedding'. \"\n",
    "          \"No candidate resumes to score. 'processed_candidate_data' will be empty.\")\n",
    "else:\n",
    "    # Proceed with scoring if all checks pass\n",
    "    print(f\"INFO: Starting similarity score calculation for {len(final_resume_paths_for_embedding)} candidate resume(s) \"\n",
    "          f\"against {len(sample_paths_processed)} sample resume profile(s)...\")\n",
    "\n",
    "    # --- Main Scoring Loop ---\n",
    "    # Iterate through each candidate resume's embedding and its corresponding path\n",
    "    for resume_idx, current_resume_embedding_vector in enumerate(resume_embeddings):\n",
    "        candidate_original_path = final_resume_paths_for_embedding[resume_idx]\n",
    "        candidate_original_filename = os.path.basename(candidate_original_path)\n",
    "        \n",
    "        # Store similarities of this candidate with all samples\n",
    "        similarities_with_all_samples = []\n",
    "        \n",
    "        # Iterate through each sample resume's embedding and its corresponding path\n",
    "        for sample_idx, current_sample_embedding_vector in enumerate(sample_embeddings):\n",
    "            sample_original_path = sample_paths_processed[sample_idx]\n",
    "            sample_original_filename = os.path.basename(sample_original_path)\n",
    "            \n",
    "            try:\n",
    "                # Calculate cosine similarity. Reshape embeddings to 2D arrays as expected by cosine_similarity.\n",
    "                similarity_score_value = cosine_similarity(\n",
    "                    current_resume_embedding_vector.reshape(1, -1), \n",
    "                    current_sample_embedding_vector.reshape(1, -1)\n",
    "                )[0][0] # Extract the single similarity value\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: Cosine similarity calculation failed for candidate '{candidate_original_filename}' \"\n",
    "                      f\"with sample '{sample_original_filename}'. Score set to 0.0. Error: {e}\")\n",
    "                similarity_score_value = 0.0 \n",
    "\n",
    "            similarities_with_all_samples.append({\n",
    "                \"score\": similarity_score_value,\n",
    "                \"matched_sample_path\": sample_original_path,\n",
    "                \"matched_sample_filename\": sample_original_filename\n",
    "            })\n",
    "        \n",
    "        # Find the best match for the current candidate if any similarities were calculated\n",
    "        if similarities_with_all_samples:\n",
    "            best_match_details = max(similarities_with_all_samples, key=lambda x: x[\"score\"])\n",
    "            \n",
    "            processed_candidate_data.append({\n",
    "                \"candidate_path\": candidate_original_path,\n",
    "                \"candidate_filename\": candidate_original_filename,\n",
    "                \"best_score\": best_match_details[\"score\"],\n",
    "                \"best_matching_sample_path\": best_match_details[\"matched_sample_path\"],\n",
    "                \"best_matching_sample_filename\": best_match_details[\"matched_sample_filename\"]\n",
    "            })\n",
    "        else:\n",
    "            # This case should ideally not happen if sample_embeddings is not empty,\n",
    "            # but it's a safeguard.\n",
    "            print(f\"WARNING: No similarity scores calculated for candidate '{candidate_original_filename}'. Using default scores.\")\n",
    "            processed_candidate_data.append({\n",
    "                \"candidate_path\": candidate_original_path,\n",
    "                \"candidate_filename\": candidate_original_filename,\n",
    "                **DEFAULT_SCORE_INFO_FOR_CANDIDATE\n",
    "            })\n",
    "\n",
    "    print(f\"INFO: Finished calculating similarity scores. \"\n",
    "          f\"Generated detailed scoring data for {len(processed_candidate_data)} candidate resume(s).\")\n",
    "\n",
    "# --- Optional: Verification of 'processed_candidate_data' ---\n",
    "INSPECT_PROCESSED_CANDIDATE_DATA_OUTPUT = True # Set to True for debugging\n",
    "\n",
    "if INSPECT_PROCESSED_CANDIDATE_DATA_OUTPUT:\n",
    "    if processed_candidate_data:\n",
    "        # Modified to print all entries instead of just a sample\n",
    "        print(f\"\\n--- Detailed Scores for All Processed Candidates ({len(processed_candidate_data)} Total) ---\")\n",
    "        for i, data_item in enumerate(processed_candidate_data): # Iterate through ALL items\n",
    "            print(f\"\\nCandidate File: {data_item.get('candidate_filename', 'N/A')} (Item {i+1})\")\n",
    "            print(f\"  Best Score: {data_item.get('best_score', 0.0):.4f}\") # Format score to 4 decimal places\n",
    "            print(f\"  Best Matching Sample: {data_item.get('best_matching_sample_filename', 'N/A')}\")\n",
    "            print(\"-\" * 40) # Separator for readability\n",
    "        print(f\"--- End of Detailed Scores for All Processed Candidates ---\")\n",
    "    else:\n",
    "        print(\"\\nINFO: 'processed_candidate_data' is empty. Nothing to inspect from scoring.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO: Starting selection and copying of candidate resumes to 'c:\\Users\\harry\\OneDrive\\Desktop\\AI RESUME SCANNER\\AI_RESUME_SCANNER\\selected_resume\\2025-05-18'.\n",
      "INFO: Selection threshold for 'best_score' is >= 0.88 (i.e., 88 on a 0-100 scale for filename).\n",
      "INFO: Finished selection process. Successfully copied 5 resume(s) to 'c:\\Users\\harry\\OneDrive\\Desktop\\AI RESUME SCANNER\\AI_RESUME_SCANNER\\selected_resume\\2025-05-18'.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell: Filter Candidate Resumes and Copy Selected Ones with Enriched Filenames ---\n",
    "\n",
    "# This cell takes the 'processed_candidate_data' list (generated by the previous\n",
    "# \"scoring\" cell) and filters candidates based on their 'best_score'.\n",
    "# For selected candidates, it constructs a new filename that includes the score\n",
    "# and an identifier of the best matching sample resume. It then copies the original\n",
    "# candidate resume file to the 'destination_folder' using this new filename.\n",
    "\n",
    "# --- Prerequisites ---\n",
    "# Expected variables from previous cells:\n",
    "#   - 'processed_candidate_data': A list of dictionaries. Each dictionary must contain:\n",
    "#       - 'candidate_path': Full path to the original candidate resume file.\n",
    "#       - 'candidate_filename': The original filename of the candidate resume.\n",
    "#       - 'best_score': The calculated best similarity score (float, e.g., 0.0 to 1.0).\n",
    "#       - 'best_matching_sample_filename': The filename of the sample resume that yielded the best_score.\n",
    "#   - 'destination_folder': The path to the directory where selected resumes will be copied\n",
    "#                           (e.g., \"AI_RESUME_SCANNER/selected_resume/YYYY-MM-DD\").\n",
    "#     This folder should have been created by 'os.makedirs(destination_folder, exist_ok=True)' previously.\n",
    "#\n",
    "# Required imported modules:\n",
    "#   - 'os' (for os.path.basename, os.path.join, os.path.splitext, os.path.exists)\n",
    "#   - 'shutil' (for shutil.copy)\n",
    "\n",
    "# --- Configuration for Selection and Naming ---\n",
    "# Define the similarity threshold for selecting a resume. This should be consistent\n",
    "# with how scores were interpreted (e.g., if higher is better).\n",
    "# Scores from cosine_similarity with SentenceTransformer embeddings are typically between -1.0 and 1.0,\n",
    "# but often practically between 0.0 and 1.0 for similar documents.\n",
    "SELECTION_THRESHOLD = 0.88  # Example threshold. Adjust based on your scoring scale and desired selectivity.\n",
    "\n",
    "# Counter for the number of resumes selected and copied.\n",
    "selected_resumes_count = 0\n",
    "\n",
    "print(f\"\\nINFO: Starting selection and copying of candidate resumes to '{os.path.abspath(destination_folder)}'.\")\n",
    "print(f\"INFO: Selection threshold for 'best_score' is >= {SELECTION_THRESHOLD:.2f} (i.e., {SELECTION_THRESHOLD*100:.0f} on a 0-100 scale for filename).\")\n",
    "\n",
    "# Check if 'processed_candidate_data' is available and is a non-empty list.\n",
    "if 'processed_candidate_data' in locals() and \\\n",
    "   isinstance(processed_candidate_data, list) and \\\n",
    "   processed_candidate_data:\n",
    "\n",
    "    # Iterate through each item in the 'processed_candidate_data' list.\n",
    "    # Each 'candidate_info' is a dictionary with scoring details.\n",
    "    for candidate_info in processed_candidate_data:\n",
    "        \n",
    "        # Validate the structure of the dictionary item.\n",
    "        if not isinstance(candidate_info, dict) or \\\n",
    "           not all(key in candidate_info for key in [\"candidate_path\", \n",
    "                                                     \"candidate_filename\", \n",
    "                                                     \"best_score\", \n",
    "                                                     \"best_matching_sample_filename\"]):\n",
    "            print(f\"WARNING: Skipping an invalid or incomplete data item in 'processed_candidate_data': {candidate_info}\")\n",
    "            continue\n",
    "\n",
    "        original_candidate_file_path = candidate_info[\"candidate_path\"]\n",
    "        original_candidate_filename = candidate_info[\"candidate_filename\"]\n",
    "        candidate_best_score = candidate_info[\"best_score\"]\n",
    "        matched_sample_filename_raw = candidate_info[\"best_matching_sample_filename\"]\n",
    "\n",
    "        # Apply the selection threshold to the 'best_score'.\n",
    "        if candidate_best_score >= SELECTION_THRESHOLD:\n",
    "            selected_resumes_count += 1\n",
    "            \n",
    "            # --- Construct the new, informative filename ---\n",
    "            # Convert score to a 0-100 integer string for readability in the filename.\n",
    "            score_for_filename = str(int(candidate_best_score * 100)) \n",
    "            \n",
    "            # Get an identifier for the matched sample (e.g., filename without its extension).\n",
    "            # Handle the 'N/A' case if no sample was matched (e.g., due to empty sample_embeddings).\n",
    "            matched_sample_identifier = \"NoMatchingSample\" # Default if 'N/A'\n",
    "            if matched_sample_filename_raw != \"N/A\" and isinstance(matched_sample_filename_raw, str):\n",
    "                # Use os.path.splitext to get filename without extension. [0] is the name, [1] is the ext.\n",
    "                matched_sample_identifier = os.path.splitext(matched_sample_filename_raw)[0]\n",
    "                # Optional: Sanitize matched_sample_identifier if it might contain problematic characters for filenames.\n",
    "                # For example, replace spaces or special characters.\n",
    "                # matched_sample_identifier = matched_sample_identifier.replace(\" \", \"_\") \n",
    "            \n",
    "            # New filename format: \"{Score}_matchedWith_{SampleNameIdentifier}_{OriginalCandidateFilename}\"\n",
    "            # Example: \"75_matchedWith_SampleResumeA_JohnDoe_Resume.pdf\"\n",
    "            new_filename = f\"{score_for_filename}_matchedWith_{matched_sample_identifier}_{original_candidate_filename}\"\n",
    "            \n",
    "            # Full path for the destination file.\n",
    "            destination_file_path = os.path.join(destination_folder, new_filename)\n",
    "            \n",
    "            # --- Copy the original resume file to the destination with the new name ---\n",
    "            try:\n",
    "                # First, ensure the source file (original candidate resume) actually exists.\n",
    "                if os.path.exists(original_candidate_file_path):\n",
    "                    shutil.copy(original_candidate_file_path, destination_file_path)\n",
    "                    # print(f\"  SUCCESS: Copied '{original_candidate_filename}' to '{new_filename}'\") # Optional success log per file\n",
    "                else:\n",
    "                    print(f\"ERROR: Source resume file not found, cannot copy: '{original_candidate_file_path}' \"\n",
    "                          f\"for new file '{new_filename}'.\")\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: Could not copy file '{original_candidate_filename}' to '{destination_file_path}'. \"\n",
    "                      f\"Error: {e}\")\n",
    "    \n",
    "    # --- Final Summary ---\n",
    "    if selected_resumes_count > 0:\n",
    "        print(f\"INFO: Finished selection process. Successfully copied {selected_resumes_count} resume(s) \"\n",
    "              f\"to '{os.path.abspath(destination_folder)}'.\")\n",
    "    else:\n",
    "        print(f\"INFO: Finished selection process. No candidate resumes met the selection threshold \"\n",
    "              f\"of >= {SELECTION_THRESHOLD:.2f} (score {SELECTION_THRESHOLD*100:.0f}).\")\n",
    "\n",
    "elif not ('processed_candidate_data' in locals() and isinstance(processed_candidate_data, list)):\n",
    "    print(\"ERROR: 'processed_candidate_data' list is not defined or not a list. \"\n",
    "          \"Cannot perform resume selection and copying.\")\n",
    "else: # 'processed_candidate_data' is an empty list\n",
    "    print(\"INFO: 'processed_candidate_data' is empty. \"\n",
    "          \"No candidate resumes were scored in the previous step, so no files to select or copy.\")\n",
    "\n",
    "# --- End of File Selection, Renaming, and Copying Cell ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resumevenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
